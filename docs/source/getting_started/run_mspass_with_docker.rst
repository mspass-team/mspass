.. _run_mspass_with_docker:

Run MsPASS with Docker
======================

Prerequisites
-------------

Docker is required for users to run MsPASS. 
It is a piece of software to create containers (lightweight virtual machine) that will run on your machine. 
To install Docker on machines that you have root access, please refer to the guide `here <https://docs.docker.com/get-docker/>`__ and follow the instructions for your specific platform. 
Docker is well-supported on all popular operating systems. 
Please make sure Docker is correctly installed and the Docker Engine is running in the background before proceeding to the next step.

Download MsPASS Container
-------------------------

The MsPASS container image is built and hosted on `Docker Hub <https://hub.docker.com/r/mspass/mspass>`__. 
It is also available in the `GitHub Container Registry <https://github.com/mspass-team/mspass/pkgs/container/mspass>`__.
Once you have docker setup properly, use the following command in a terminal to pull the MsPASS image from Docker Hub to your local machine:

.. code-block:: 

    docker pull mspass/mspass

Be patient as this can take a few minutes depending on your internet speed. 
Note you can run this command from anywhere. 
It loads data only in Docker's data space so you will not see anything happen in the directory where you run this command but it will eat up several hundred megabytes on your disk. 
Any data created and stored inside the container will be opaque from the local system (outside) except for the ones in the directories that are mounted to the container.

It can be confusing to understand where data is stored in a containerized environment. 
In the discussion below files or data we reference that reside in a container will be set in italics.
Local files/data will be referred to with normal font text.


Run MsPASS Container in All-in-one Mode
---------------------------------------

To run MsPASS in its default setting, use this command:

.. code-block:: 

    docker run -p 8888:8888 mspass/mspass

The ``-p 8888:8888`` argument maps host's ``8888`` port to the container's ``8888`` port. 
Note that ``8888`` is the default port for the Jupyter Notebook frontend. 
If there are collisions with the ``8888`` port on the host, change the first number (e.g. to use port ``9999`` on the host use ``-p 9999:8888``.)

Now, you can use the link printed on the output that starts with ``http://127.0.0.1/`` to access the notebook and run codes within the container.
If you are not familiar with Jupyter Notebook, please refer to its `documentation <https://jupyter-notebook.readthedocs.io/en/stable/ui_components.html>`__ on how to use the user interface.
The root directory of the notebook contains three different directories: *db*, *logs*, and *work*.
*db* contains MongoDB's database files. 
*logs* contains the logs generated by the database, the scheduler, and the worker.
*work* is the worker's local scratch space. 
Because no mounting arguments were given to the ``docker run`` command above, any files you created will stay in the container, and will be removed when the container is removed.
That is rarely the mode used, but we began there to emphasize a limitation of the default.  
The next paragraph describes the more common usage. 
To shut down and exit the container, you can either click the "Quit" button of the Notebook Dashboard or simply use Control-C.

Normally you usually will want to mount a local file system containing your data to make that data 
accessible to the workflow you want to run in the container.  
For example, to mount the current directory on your system to the container and 
define that as */home*, use this command:

.. code-block:: 

    docker run -p 8888:8888 --mount src=`pwd`,target=/home,type=bind mspass/mspass

The ``--mount`` option binds current directory on your system to */home* within the container. 
*/home* is the root directory of the notebook. 
This option keeps the files outside of the container, so your data will be accessible after the container is removed. 
Note after that line is run you will see db, logs, and work directories were created in the directory from 
which you ran that command.   Similarly, continue processing after a previous successful run 
you can cd to that directory and run the above command again.   
