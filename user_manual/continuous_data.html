

<!DOCTYPE html>
<html class="writer-html5" lang="en">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Continuous Data Handling with MsPASS &mdash; MsPASS 0.0.1 documentation</title>
      <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=b86133f3" />
      <link rel="stylesheet" type="text/css" href="../_static/css/theme.css?v=e59714d7" />
      <link rel="stylesheet" type="text/css" href="../_static/copybutton.css?v=76b2166b" />

  
      <script src="../_static/jquery.js?v=5d32c60e"></script>
      <script src="../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js?v=f6245a2f"></script>
      <script src="../_static/doctools.js?v=888ff710"></script>
      <script src="../_static/sphinx_highlight.js?v=4825356b"></script>
      <script src="../_static/clipboard.min.js?v=a7894cd8"></script>
      <script src="../_static/copybutton.js?v=f281be69"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="What database schema should I use?" href="schema_choices.html" />
    <link rel="prev" title="Processing History Concepts" href="processing_history_concepts.html" />  

  <style>
    .wy-nav-content { max-width: 1600px; }
  </style>

  
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../index.html" class="icon icon-home">
            MsPASS
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
    
              <p class="caption" role="heading"><span class="caption-text">Getting Started</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../getting_started/quick_start.html">Getting Started in a Nutshell</a></li>
<li class="toctree-l1"><a class="reference internal" href="../getting_started/run_mspass_with_docker.html">Run MsPASS with Docker</a></li>
<li class="toctree-l1"><a class="reference internal" href="../getting_started/deploy_mspass_with_docker_compose.html">Deploy MsPASS with Docker Compose</a></li>
<li class="toctree-l1"><a class="reference internal" href="../getting_started/deploy_mspass_with_conda.html">Deploy MsPASS with Conda</a></li>
<li class="toctree-l1"><a class="reference internal" href="../getting_started/deploy_mspass_with_conda.html#advanced-setup-considerations">Advanced Setup Considerations</a></li>
<li class="toctree-l1"><a class="reference internal" href="../getting_started/deploy_mspass_on_HPC.html">Deploying MsPASS on an HPC cluster</a></li>
<li class="toctree-l1"><a class="reference internal" href="../getting_started/deploy_mspass_with_conda_and_coiled.html">Deploy MsPASS with Conda and Coiled</a></li>
<li class="toctree-l1"><a class="reference internal" href="../getting_started/getting_started_overview.html">MsPASS Virtual Cluster Concepts</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Introduction</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="introduction.html">Introduction</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Data Management</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="database_concepts.html">Database Concepts</a></li>
<li class="toctree-l1"><a class="reference internal" href="CRUD_operations.html">CRUD Operations in MsPASS</a></li>
<li class="toctree-l1"><a class="reference internal" href="mongodb_and_mspass.html">Using MongoDB with MsPASS</a></li>
<li class="toctree-l1"><a class="reference internal" href="normalization.html">Normalization</a></li>
<li class="toctree-l1"><a class="reference internal" href="importing_tabular_data.html">Importing Tabular Data</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Seismic Data Objects</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="data_object_design_concepts.html">Data Object Design Concepts</a></li>
<li class="toctree-l1"><a class="reference internal" href="numpy_scipy_interface.html">Using numpy/scipy with MsPASS</a></li>
<li class="toctree-l1"><a class="reference internal" href="obspy_interface.html">Using ObsPy with MsPASS</a></li>
<li class="toctree-l1"><a class="reference internal" href="time_standard_constraints.html">Time Standard Constraints</a></li>
<li class="toctree-l1"><a class="reference internal" href="processing_history_concepts.html">Processing History Concepts</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Continuous Data Handling with MsPASS</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#concepts">Concepts</a></li>
<li class="toctree-l2"><a class="reference internal" href="#gap-processing">Gap Processing</a></li>
<li class="toctree-l2"><a class="reference internal" href="#merging-data-segments">Merging Data Segments</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#read-data-merge-algorithm">read_data merge algorithm</a></li>
<li class="toctree-l3"><a class="reference internal" href="#mspass-merge-function">MsPASS merge function</a></li>
<li class="toctree-l3"><a class="reference internal" href="#timeintervalreader">TimeIntervalReader</a></li>
<li class="toctree-l3"><a class="reference internal" href="#examples">Examples</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="schema_choices.html">What database schema should I use?</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Data Processing</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="algorithms.html">Algorithms</a></li>
<li class="toctree-l1"><a class="reference internal" href="importing_data.html">Importing Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="handling_errors.html">Handling Errors</a></li>
<li class="toctree-l1"><a class="reference internal" href="data_editing.html">Data Editing</a></li>
<li class="toctree-l1"><a class="reference internal" href="cleaning_metadata.html">Cleaning Inconsistent Metadata</a></li>
<li class="toctree-l1"><a class="reference internal" href="header_math.html">Header (Metadata) Math</a></li>
<li class="toctree-l1"><a class="reference internal" href="graphics.html">Graphics in MsPASS</a></li>
<li class="toctree-l1"><a class="reference internal" href="signal_to_noise.html">Signal to Noise Ratio Estimation</a></li>
<li class="toctree-l1"><a class="reference internal" href="adapting_algorithms.html">Adapting an Existing Algorithm to MsPASS</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">System Tuning</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="parallel_processing.html">Parallel Processing</a></li>
<li class="toctree-l1"><a class="reference internal" href="memory_management.html">Memory Management</a></li>
<li class="toctree-l1"><a class="reference internal" href="io.html">I/O in MsPASS</a></li>
<li class="toctree-l1"><a class="reference internal" href="parallel_io.html">Parallel IO in MsPASS</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">FAQ</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="FAQ.html">Frequency Asked Questions (FAQ)</a></li>
<li class="toctree-l1"><a class="reference internal" href="development_strategies.html">How do I develop a new workflow from scratch?</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Reference Manual</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../python_api/index.html">Python API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cxx_api/index.html">C++ API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mspass_schema/mspass_schema.html">MsPASS Schema</a></li>
</ul>

    <a href= "../genindex.html">Index</a>
  
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">MsPASS</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">Continuous Data Handling with MsPASS</li>
      <li class="wy-breadcrumbs-aside">
              <a href="https://github.com/mspass-team/mspass/blob/master/docs/source/user_manual/continuous_data.rst" class="fa fa-github"> Edit on GitHub</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="continuous-data-handling-with-mspass">
<span id="continuous-data"></span><h1>Continuous Data Handling with MsPASS<a class="headerlink" href="#continuous-data-handling-with-mspass" title="Permalink to this heading">ÔÉÅ</a></h1>
<section id="concepts">
<h2>Concepts<a class="headerlink" href="#concepts" title="Permalink to this heading">ÔÉÅ</a></h2>
<p>Seismologists universally use the term ‚Äúcontinuous data‚Äù to mean
long time series records with no significant gaps.   The term is
actually potentially confusing because the data are not really continuous
at all but sampled at a fixed sample interval, nor are they of infinite duration
which might be implied if you were discussing Fourier transforms on functions.
In practice, ‚Äúcontinuous data‚Äù in seismology means a series of
windowed segments that can be merged to form a longer window of data.
The maximum length possible is the duration of data recording.
The process of gluing (merging) multiple segments is, more or less,
the inverse of cutting a shorter window out of a longer window of data.
Gluing/merging data algorithms have to deal with some different issues
than windowing.</p>
<p>Some important issues about common practice and the reality of real
data are:</p>
<ol class="arabic simple">
<li><p>There are two common choices for how the data are blocked:
(1) day volumes, and (2)  raw digitizer files of irregular length
created when the digitizer does a memory dump (All current
generation digitizers write to an internal memory buffer that is
dumped when the memory use exceeds a high water mark.)  In either case
there is some explicit or implicit (e.g. file naming convention)
that provides a hint of the order of the segments.</p></li>
<li><p>A large fraction of data contain various types of ‚Äúdata gaps‚Äù.
Gaps occur for a long list of reasons that are mostly unimportant
when analyzing such data.  What is important is that data gaps
span a range of time scales from a single sample to years.</p></li>
<li><p>A less-common problem is a data overlap.  An overlap occurs when
two segments you need to merge have conflicting time stamps.
To make this clear it is helpful to review two MsPASS concepts in
the TimeSeries and Seismogram data objects.  Let <em>d1</em> and <em>d2</em> be
two <a class="reference internal" href="../python_api/mspasspy.ccore.html#mspasspy.ccore.seismic.TimeSeries" title="mspasspy.ccore.seismic.TimeSeries"><code class="xref py py-class docutils literal notranslate"><span class="pre">TimeSeries</span></code></a> objects that are successive segments we
expect to merge with <em>d2</em> being the segment following <em>d1</em> in time.
In MsPASS we use the attribute <em>t0</em> (alternatively the method
<em>starttime</em>) for the time of sample 0.  We also use the method
<em>endtime</em> to get the computed time of the last data sample.  An
overlap is present between these two segments when
<em>d2.t0 &lt; d1.endtime()</em>.
We know of three ways overlaps can
occur:  (1) timing problems with the instrument that recorded the
data, (2) hardware or software issues in recording instrument that
cause packets to be duplicated in memory before they are dumped, and
(3) blunders in data management where duplicate files are indexed
and defined in a database wf collection (wfdisc table in Antelope).</p></li>
</ol>
<p>MsPASS has some capabilities for merging data within the realities of
real data noted above.   These are discussed in the section below.
MsPASS does not, however, substitute for nitty-gritty details network
and experiment operators have to face in cleaning field data for archive.
We consider that as a problem already solved by Earthscope,
the USGS, and global network operators in systems they
use for creating the modern data archive of the FDSN.  Custom
experimental data may need to utilize Earthscope tools to fix problems not
covered by MsPASS.</p>
</section>
<section id="gap-processing">
<h2>Gap Processing<a class="headerlink" href="#gap-processing" title="Permalink to this heading">ÔÉÅ</a></h2>
<p>Internally MsPASS handles data gaps with a subclass of the
<a class="reference internal" href="../python_api/mspasspy.ccore.html#mspasspy.ccore.seismic.TimeSeries" title="mspasspy.ccore.seismic.TimeSeries"><code class="xref py py-class docutils literal notranslate"><span class="pre">TimeSeries</span></code></a> called <code class="xref py py-class docutils literal notranslate"><span class="pre">TimeSeriesWGaps&lt;mspasspy.ccore.seismic.TimeSeriesWGaps&gt;`</span></code>.   That extension of
<a class="reference internal" href="../python_api/mspasspy.ccore.html#mspasspy.ccore.seismic.TimeSeries" title="mspasspy.ccore.seismic.TimeSeries"><code class="xref py py-class docutils literal notranslate"><span class="pre">TimeSeries</span></code></a> is written in C++ and is documented
<a class="reference external" href="https://www.mspass.org/cxx_api/mspass.html#mspass-namespace">here</a>.
Like <a class="reference internal" href="../python_api/mspasspy.ccore.html#mspasspy.ccore.seismic.TimeSeries" title="mspasspy.ccore.seismic.TimeSeries"><code class="xref py py-class docutils literal notranslate"><span class="pre">TimeSeries</span></code></a> this class has python bindings created
with pybind11.  All the methods described in the C++ documentation
page have python bindings.  There are methods for defining gaps,
zeroing data in defined gaps, and deleting gaps.
See the doxygen pages linked above for details.
The python functions that currently deal with data gaps have a second
strategy for handling his problem best described in the context
of those functions.</p>
</section>
<section id="merging-data-segments">
<h2>Merging Data Segments<a class="headerlink" href="#merging-data-segments" title="Permalink to this heading">ÔÉÅ</a></h2>
<p>There are currently two different methods in MsPASS to handle merging
continuous data segments:  (1) a special, implicit option of the
<a class="reference internal" href="../python_api/mspasspy.db.html#mspasspy.db.database.Database.read_data" title="mspasspy.db.database.Database.read_data"><code class="xref py py-meth docutils literal notranslate"><span class="pre">read_data</span></code></a> method of the
<a class="reference internal" href="../python_api/mspasspy.db.html#mspasspy.db.database.Database" title="mspasspy.db.database.Database"><code class="xref py py-class docutils literal notranslate"><span class="pre">Database</span></code></a> class, and (2) the
processing function <a class="reference internal" href="../python_api/mspasspy.algorithms.html#mspasspy.algorithms.window.merge" title="mspasspy.algorithms.window.merge"><code class="xref py py-func docutils literal notranslate"><span class="pre">merge</span></code></a>.
In addition, there is a special reader function called
<code class="xref py py-func docutils literal notranslate"><span class="pre">TimeIntervalReader</span></code> that can be used
to read fixed time windows of data.  That function uses
<a class="reference internal" href="../python_api/mspasspy.algorithms.html#mspasspy.algorithms.window.merge" title="mspasspy.algorithms.window.merge"><code class="xref py py-func docutils literal notranslate"><span class="pre">merge</span></code></a>
to do gap and overlap repair.</p>
<section id="read-data-merge-algorithm">
<h3>read_data merge algorithm<a class="headerlink" href="#read-data-merge-algorithm" title="Permalink to this heading">ÔÉÅ</a></h3>
<p>This approach is only relevant if you have raw miniseed files you
plan to read to initiate your processing sequence.  The miniseed format
uses a packet structure with each packet normally defining a single
channel (Note the standard allows multiplexed data but none of us have
ever encountered such data.).   The order of the packets is used by
all readers we know of to determine if a sequence of packets are a single
waveform.   If the station codes (‚Äúnet‚Äù, ‚Äústa‚Äù, ‚Äúchan‚Äù, and ‚Äúloc‚Äù attributes
in all MsPASS schemas) change in a sequence of packets readers
universally assume that is the end of a given segment.  How readers handle
a second issue is, however, variable.  Each miniseed packet has a time
tag that is comparable to the <cite>t0</cite> attribute of a <a class="reference internal" href="../python_api/mspasspy.ccore.html#mspasspy.ccore.seismic.TimeSeries" title="mspasspy.ccore.seismic.TimeSeries"><code class="xref py py-class docutils literal notranslate"><span class="pre">TimeSeries</span></code></a> object
and end time field equivalent to the output of the <a class="reference internal" href="../python_api/mspasspy.ccore.html#mspasspy.ccore.seismic.TimeSeries" title="mspasspy.ccore.seismic.TimeSeries"><code class="xref py py-class docutils literal notranslate"><span class="pre">TimeSeries</span></code></a>
endtime method.   If the <cite>t0</cite> value of a packet is greater than some
fractional tolerance of 1 sample more than the endtime of the previous
packet, a reader will invoke a gap handler.  A reader‚Äôs gap handler
commonly has options for what to do with different kinds of ‚Äúgaps‚Äù, but
for this section our definition is defined by the way obspy
handles this problem with their <code class="xref py py-class docutils literal notranslate"><span class="pre">Stream</span></code> merge method described
<a class="reference external" href="https://docs.obspy.org/packages/autogen/obspy.core.stream.Stream.merge.html">here</a>.
That particular algorithm is invoked when reading miniseed data
if and only if a block of data defined running the mspass
function <a class="reference internal" href="../python_api/mspasspy.db.html#mspasspy.db.database.Database.index_mseed_file" title="mspasspy.db.database.Database.index_mseed_file"><code class="xref py py-meth docutils literal notranslate"><span class="pre">index_mseed_file</span></code></a> is
run with the optional argument <cite>segment_time_tears</cite> is set False.
(Note the default is True.).   If you need to use this approach, you will
need to also take care in defining the value of the following arguments
that are passed to obspy‚Äôs merge function for gap handle:
<cite>merge_method</cite>, <cite>merge_fill_value</cite>, and <cite>merge_interpolation_samples</cite>.
Those three arguments are passed directly to obspy merge arguments with
a variant of the same names:  <cite>method</cite>, <cite>fill_value</cite>, and <cite>interpolation_samples</cite>.</p>
<p>Note an alternative user‚Äôs who have previously used obspy for this functionality
may want to consider is to write a custom function that utilizes obspy‚Äôs merge
directly rather than the implied used in read_data.</p>
</section>
<section id="mspass-merge-function">
<h3>MsPASS merge function<a class="headerlink" href="#mspass-merge-function" title="Permalink to this heading">ÔÉÅ</a></h3>
<p>MsPASS has a native version of a function with a capability similar to
the obspy merge function noted above.  The MsPASS function add some additional
features and, although not verified by formal testing,
is likely much faster than the obpsy version due to fundamental differences
in the implementation.
The docstring for <a class="reference internal" href="../python_api/mspasspy.algorithms.html#mspasspy.algorithms.window.merge" title="mspasspy.algorithms.window.merge"><code class="xref py py-func docutils literal notranslate"><span class="pre">merge</span></code></a> describes more
details but some key features of this function are:</p>
<ul class="simple">
<li><p>Like obspy‚Äôs function of the same name its purpose is to glue/merge
a set of waveform components into a single, continuous time series.
A key difference is that the obspy function requires an obspy
Stream object as input while the MsPASS function uses the ‚Äúmember‚Äù
container of a <code class="xref py py-class docutils literal notranslate"><span class="pre">TimeSeriesEnsemble</span></code> object as input.</p></li>
<li><p>It provides for an optional windowing of the merged result.  That approach
is useful, for example, for carving events out from a local archive of
continuous waveform data in a single step. This feature is useful for
reducing the memory footprint of a parallel job.</p></li>
<li><p>Gaps are flagged and posted with a Metadata approach.  Obspy has a set of
options for gap handling that are inseparable from the function.
Any detected gaps in the
MsPASS merge function are posted to the Metadata component of the
<a class="reference internal" href="../python_api/mspasspy.ccore.html#mspasspy.ccore.seismic.TimeSeries" title="mspasspy.ccore.seismic.TimeSeries"><code class="xref py py-class docutils literal notranslate"><span class="pre">TimeSeries</span></code></a> it returns accessible with the key ‚Äúgaps‚Äù.
The content of the ‚Äúgaps‚Äù attribute is a list of one or more
python dictionaries with the keyworks ‚Äústarttime‚Äù and ‚Äúendtime‚Äù
defining the epoch time range of all gaps in the returned datum.
The function also has an optional ‚Äúzero_gaps‚Äù.  When set True
(default is False) any gaps are explicitly set to zeros.   By default
the values should be treated as undefined, although in practice they
are likely zeros.</p></li>
<li><p>Overlap handling is controlled by another boolean parameter
with the name ‚Äúfix_overlaps‚Äù.   When set True the function will
check for overlapping data and attempt to repair overlaps only if
the sample numerical data match within machine tolerance.
The default behavior is to mark the return dead if any overlap is
detected.  Obspy uses a less dogmatic algorithm driven by an optional
function argument called ‚Äúinterpolation_samples‚Äù.  As noted above it has
been our experience that, in general, overlapping data always indicate
a data quality problem that invalidates the data when the samples
do not match.  If you need
the obspy functionality use the
<a class="reference internal" href="../python_api/mspasspy.util.html#mspasspy.util.converter.TimeSeriesEnsemble2Stream" title="mspasspy.util.converter.TimeSeriesEnsemble2Stream"><code class="xref py py-func docutils literal notranslate"><span class="pre">TimeSeriesEnsemble2Stream</span></code></a> and the
inverse <code class="xref py py-func docutils literal notranslate"><span class="pre">Trace2TimeSeriesEnsemble</span></code>
to create the obspy input and then restore the returned data to
the MsPASS internal data structures</p></li>
</ul>
</section>
<section id="timeintervalreader">
<h3>TimeIntervalReader<a class="headerlink" href="#timeintervalreader" title="Permalink to this heading">ÔÉÅ</a></h3>
<p>A second MsPASS tool for working with continuous data is a function
with the descriptive name
<code class="xref py py-func docutils literal notranslate"><span class="pre">TimeIntervalReader</span></code>.
It is designed to do the high-level task of cutting a fixed time
interval of data from one or more channels of a continuous data archive.
This function is built on top of the lower-level
<a class="reference internal" href="../python_api/mspasspy.algorithms.html#mspasspy.algorithms.window.merge" title="mspasspy.algorithms.window.merge"><code class="xref py py-func docutils literal notranslate"><span class="pre">merge</span></code></a> but is best thought of as
an alternative reader to create ensembles cut from a continuous data archive.
For that reason the required arguments are a database handle and the
time interval of data to be extracted from the archive.  Gap and overlap
handling is handled by <a class="reference internal" href="../python_api/mspasspy.algorithms.html#mspasspy.algorithms.window.merge" title="mspasspy.algorithms.window.merge"><code class="xref py py-func docutils literal notranslate"><span class="pre">merge</span></code></a>.</p>
</section>
<section id="examples">
<h3>Examples<a class="headerlink" href="#examples" title="Permalink to this heading">ÔÉÅ</a></h3>
<p><em>Example 1:  Create a single waveform in a defined time window
from continuous data archive.</em>
This script will create a longer <a class="reference internal" href="../python_api/mspasspy.ccore.html#mspasspy.ccore.seismic.TimeSeries" title="mspasspy.ccore.seismic.TimeSeries"><code class="xref py py-class docutils literal notranslate"><span class="pre">TimeSeries</span></code></a> object from a set day files
for the BHZ channel of GSN station AAK.   Ranges are constant for a simple
illustration:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># code above would define database handle db</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">mspasspy.algorithms.window</span><span class="w"> </span><span class="kn">import</span> <span class="n">merge</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">obspy</span><span class="w"> </span><span class="kn">import</span> <span class="n">UTCDateTime</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">bson</span><span class="w"> </span><span class="kn">import</span> <span class="n">json_utils</span>  <span class="c1">#TODO  verify this is right</span>
<span class="n">net</span> <span class="o">=</span><span class="s2">&quot;II&quot;</span>
<span class="n">sta</span><span class="o">=</span><span class="s2">&quot;AAK&quot;</span>
<span class="n">chan</span><span class="o">=</span><span class="s2">&quot;BHZ&quot;</span>
<span class="n">loc</span><span class="o">=</span><span class="s2">&quot;00&quot;</span>    <span class="c1"># STS-1 sensor at AAK</span>
<span class="c1"># TODO:   select a reasonable time interval</span>
<span class="n">output_stime</span><span class="o">=</span><span class="n">UTCDateTime</span><span class="p">()</span>
<span class="n">output_etime</span><span class="o">=</span><span class="n">UTCDateTime</span><span class="p">()</span>
<span class="c1"># this is a MongoDB query to retrieve all segments with data in the</span>
<span class="c1"># desired time range of output_stime to output_etime</span>
<span class="n">query</span> <span class="o">=</span> <span class="p">{</span>
  <span class="s2">&quot;$and&quot;</span><span class="p">:</span> <span class="p">[</span>
    <span class="p">{</span> <span class="s2">&quot;sta&quot;</span> <span class="p">:</span> <span class="p">{</span><span class="s2">&quot;$eq&quot;</span> <span class="p">:</span> <span class="n">sta</span><span class="p">}},</span>
    <span class="p">{</span> <span class="s2">&quot;net&quot;</span> <span class="p">:</span> <span class="p">{</span><span class="s2">&quot;$eq&quot;</span> <span class="p">:</span> <span class="n">net</span><span class="p">}},</span>
    <span class="p">{</span> <span class="s2">&quot;chan&quot;</span> <span class="p">:</span> <span class="p">{</span><span class="s2">&quot;$eq&quot;</span> <span class="p">:</span> <span class="n">chan</span><span class="p">}},</span>
    <span class="p">{</span> <span class="s2">&quot;loc&quot;</span> <span class="p">:</span> <span class="p">{</span><span class="s2">&quot;$eq&quot;</span> <span class="p">:</span> <span class="n">loc</span><span class="p">}},</span>
    <span class="p">{</span> <span class="s2">&quot;starttime&quot;</span> <span class="p">:</span> <span class="p">{</span><span class="s2">&quot;$lte&quot;</span> <span class="p">:</span> <span class="n">output_etime</span><span class="p">}},</span>
    <span class="p">{</span> <span class="s2">&quot;endtime&quot;</span> <span class="p">:</span> <span class="p">{</span><span class="s2">&quot;$gte&quot;</span> <span class="p">:</span> <span class="n">output_stime</span><span class="p">}}</span>
  <span class="p">]</span>
<span class="p">}</span>
<span class="n">cursor</span><span class="o">=</span><span class="n">db</span><span class="o">.</span><span class="n">wf_miniseed</span><span class="o">.</span><span class="n">find</span><span class="p">(</span><span class="n">query</span><span class="p">)</span><span class="o">.</span><span class="n">sort</span><span class="p">()</span>   <span class="c1"># TODO work out sort format</span>
<span class="n">tsens</span> <span class="o">=</span> <span class="n">db</span><span class="o">.</span><span class="n">read_data</span><span class="p">(</span><span class="n">query</span><span class="p">,</span><span class="n">collection</span><span class="o">=</span><span class="s2">&quot;wf_miniseed&quot;</span><span class="p">)</span>
<span class="k">if</span> <span class="n">tsens</span><span class="o">.</span><span class="n">live</span><span class="p">:</span>
  <span class="n">merged_data</span> <span class="o">=</span> <span class="n">merge</span><span class="p">(</span><span class="n">tsens</span><span class="o">.</span><span class="n">member</span><span class="p">,</span><span class="n">output_starttime</span><span class="p">,</span><span class="n">output_endtime</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">merged_data</span><span class="o">.</span><span class="n">live</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Output is ok and has &quot;</span><span class="p">,</span><span class="n">merged_data</span><span class="o">.</span><span class="n">npts</span><span class="p">,</span><span class="s2">&quot; data samples&quot;</span><span class="p">)</span>
  <span class="k">else</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Data have problems - gaps or overlaps caused the datum to be killed&quot;</span><span class="p">)</span>
<span class="k">else</span><span class="p">:</span>
  <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;The following query yielded no data:&quot;</span><span class="p">)</span>
  <span class="nb">print</span><span class="p">(</span><span class="n">json</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">dumps</span><span class="p">(</span><span class="n">query</span><span class="p">,</span><span class="n">indent</span><span class="o">=</span><span class="mi">2</span><span class="p">))</span>
</pre></div>
</div>
<p><em>Example 2: parallel read from continuous archive</em>  This example is a workflow
to build a dataset of waveforms
segmented around a set of previously measured P wave arrival time from
an archive of continuous data.   The example is not complete as it
requires implementing a custom function that below is given the symbolic
name ‚Äúarrivals2list‚Äù.  From that list we create a dask bag and use it
to drive a parallel read with <cite>read_distributed_data</cite> that passes a
series of enembles to a function defined at the top that runs <cite>merge</cite>.
The example is made up, but is a prototype for building an event-based
data set of all waveforms with P wave times packed the the
Earthscope Array Network Facility (ANF) available online
from Earthscope.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">mspasspy.db.DBClient</span><span class="w"> </span><span class="kn">import</span> <span class="n">DBClient</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">dask.bag</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">dbg</span>
<span class="n">dbclient</span><span class="o">=</span><span class="n">DBClient</span><span class="p">()</span>
<span class="c1"># we need two database handles.  One for the continuous data (dbc)</span>
<span class="c1"># and one to save the segments  (dbo).</span>
<span class="n">dbc</span> <span class="o">=</span> <span class="n">dbclient</span><span class="o">.</span><span class="n">get_database</span><span class="p">(</span><span class="s2">&quot;TA2010&quot;</span><span class="p">)</span>   <span class="c1"># TA continuous data from 2010</span>
<span class="n">dbo</span> <span class="o">=</span> <span class="n">dbclient</span><span class="o">.</span><span class="n">get_database</span><span class="p">(</span><span class="s2">&quot;Pdata2010&quot;</span><span class="p">)</span>  <span class="c1"># arrivals from ANF picks</span>

<span class="k">def</span><span class="w"> </span><span class="nf">query_generator</span><span class="p">(</span><span class="n">doc</span><span class="p">):</span>
<span class="w">  </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">  Generates a MongoDB query to run against wf_miniseed for waveform</span>
<span class="sd">  segments containing any of the time interval time+stwin&lt;=t&lt;=time+etwin.</span>
<span class="sd">  Returns a python dict that is used by read_distributed_data to</span>
<span class="sd">  generate a dask bag of ensembles.  Note this is an illustrative example</span>
<span class="sd">  and makes no sanity checks on inputs for simplicity.</span>

<span class="sd">  The input is the same python dict later loaded with the data using</span>
<span class="sd">  the container_to_merge argument of read_distributed_data.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">net</span> <span class="o">=</span> <span class="n">doc</span><span class="p">[</span><span class="s2">&quot;net&quot;</span><span class="p">]</span>
  <span class="n">sta</span> <span class="o">=</span> <span class="n">doc</span><span class="p">[</span><span class="s2">&quot;sta&quot;</span><span class="p">]</span>
  <span class="n">time</span> <span class="o">=</span> <span class="n">doc</span><span class="p">[</span><span class="s2">&quot;arrival_time&quot;</span><span class="p">]</span>
  <span class="n">query</span><span class="p">[</span><span class="s2">&quot;net&quot;</span><span class="p">]</span><span class="o">=</span><span class="n">net</span>
  <span class="n">query</span><span class="p">[</span><span class="s2">&quot;sta&quot;</span><span class="p">]</span><span class="o">=</span><span class="n">sta</span>
  <span class="n">stime</span><span class="o">=</span><span class="n">time</span><span class="o">+</span><span class="n">stwin</span>
  <span class="n">etime</span><span class="o">=</span><span class="n">time</span><span class="o">+</span><span class="n">etwin</span>
  <span class="n">query</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;$and&quot;</span><span class="p">:</span> <span class="p">[</span>
      <span class="p">{</span> <span class="s2">&quot;sta&quot;</span> <span class="p">:</span> <span class="p">{</span><span class="s2">&quot;$eq&quot;</span> <span class="p">:</span> <span class="n">sta</span><span class="p">}},</span>
      <span class="p">{</span> <span class="s2">&quot;net&quot;</span> <span class="p">:</span> <span class="p">{</span><span class="s2">&quot;$eq&quot;</span> <span class="p">:</span> <span class="n">net</span><span class="p">},</span>
      <span class="p">{</span> <span class="s2">&quot;starttime&quot;</span> <span class="p">:</span> <span class="p">{</span><span class="s2">&quot;$lte&quot;</span> <span class="p">:</span> <span class="n">etime</span><span class="p">}},</span>
      <span class="p">{</span> <span class="s2">&quot;endtime&quot;</span> <span class="p">:</span> <span class="p">{</span><span class="s2">&quot;$gte&quot;</span> <span class="p">:</span> <span class="n">stime</span><span class="p">}}</span>
    <span class="p">]</span>
  <span class="p">}</span>
  <span class="k">return</span> <span class="n">query</span>

<span class="k">def</span><span class="w"> </span><span class="nf">make_segments</span><span class="p">(</span><span class="n">ensemble</span><span class="p">,</span><span class="n">stwin</span><span class="p">,</span><span class="n">etwin</span><span class="p">):</span>
<span class="w">  </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">  Function used in parallel map operator to create the main output of</span>
<span class="sd">  this example workflow.  The input is assumed to be a time-sorted ensemble</span>
<span class="sd">  with all data overlapping with the time window defined by</span>
<span class="sd">    stwin &lt;= t-arrival_time &lt;= etwin</span>
<span class="sd">  where t is time of a d data sample. i.e. stwin an etwin are times relative</span>
<span class="sd">  to the arrival time.   The input ensemble is assumed to normally</span>
<span class="sd">  contain multiple channels.  The algorithm works through all channels it</span>
<span class="sd">  finds.  For each group if the number of segments is 1 it simply uses</span>
<span class="sd">  the WindowData function.  If multiple segments are present it calls the</span>
<span class="sd">  MsPASS merge function with fix_overlaps set True and with the time</span>
<span class="sd">  window requested.  That will return a single waveform segment</span>
<span class="sd">  when possible.  If the merge fails that segment will be posted but</span>
<span class="sd">  marked dead.</span>

<span class="sd">  :param ensemble:  input ensemble for a single station normally containing</span>
<span class="sd">    multiple channels.</span>
<span class="sd">  :param stwin:  output window relative start time</span>
<span class="sd">  :param etwin:  output window relative end UTCDateTime</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="c1"># handle dead (empty) ensembles cleanly returning a default constructed</span>
  <span class="c1"># datum dead by definition</span>
  <span class="k">if</span> <span class="n">ensemble</span><span class="o">.</span><span class="n">dead</span><span class="p">():</span>
    <span class="k">return</span> <span class="n">TimeSeriesEnsemble</span><span class="p">()</span>
  <span class="n">ensout</span><span class="o">=</span><span class="n">TimeSeriesEnsemble</span><span class="p">()</span>
  <span class="n">net</span> <span class="o">=</span> <span class="n">ensemble</span><span class="p">[</span><span class="s2">&quot;net&quot;</span><span class="p">]</span>

  <span class="n">sta</span> <span class="o">=</span> <span class="n">ensemble</span><span class="p">[</span><span class="s2">&quot;sta&quot;</span><span class="p">]</span>
  <span class="n">time</span> <span class="o">=</span> <span class="n">ensemble</span><span class="p">[</span><span class="s2">&quot;arrival_time&quot;</span><span class="p">]</span>
  <span class="c1"># the ensemble will usually contain multiple channels.  We have to</span>
  <span class="c1"># handle each independently</span>
  <span class="n">chanset</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>
  <span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="n">ensemble</span><span class="o">.</span><span class="n">member</span><span class="p">:</span>
    <span class="n">chan</span> <span class="o">=</span> <span class="n">d</span><span class="p">[</span><span class="s2">&quot;chan&quot;</span><span class="p">]</span>
    <span class="k">if</span> <span class="n">loc</span> <span class="ow">in</span> <span class="n">d</span><span class="p">:</span>
      <span class="n">loc</span><span class="o">=</span><span class="n">d</span><span class="p">[</span><span class="s2">&quot;loc&quot;</span><span class="p">]</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="n">loc</span><span class="o">=</span><span class="kc">None</span>
    <span class="n">chanset</span><span class="o">.</span><span class="n">add</span><span class="p">([</span><span class="n">chan</span><span class="p">,</span><span class="n">loc</span><span class="p">])</span>
  <span class="k">for</span> <span class="n">chan</span><span class="p">,</span><span class="n">loc</span> <span class="ow">in</span> <span class="n">chanset</span><span class="p">:</span>
    <span class="n">enstmp</span><span class="o">=</span><span class="n">TimeSeriesEnsemble</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="n">ensemble</span><span class="o">.</span><span class="n">member</span><span class="p">:</span>
      <span class="k">if</span> <span class="n">d</span><span class="p">[</span><span class="s2">&quot;chan&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="n">chan</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">loc</span><span class="p">:</span>
          <span class="k">if</span> <span class="n">d</span><span class="o">.</span><span class="n">is_defined</span><span class="p">(</span><span class="s2">&quot;loc&quot;</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">d</span><span class="p">[</span><span class="s2">&quot;loc&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="n">loc</span><span class="p">:</span>
              <span class="n">enstmp</span><span class="o">.</span><span class="n">member</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">d</span><span class="p">))</span>
    <span class="c1"># enstmp now has only members match chan and loc - now we can run merge</span>
    <span class="c1"># if needed.</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">enstmp</span><span class="o">.</span><span class="n">member</span><span class="p">)</span><span class="o">&gt;</span><span class="mi">1</span><span class="p">:</span>
      <span class="n">d</span> <span class="o">=</span> <span class="n">merge</span><span class="p">(</span><span class="n">enstmp</span><span class="o">.</span><span class="n">member</span><span class="p">,</span><span class="n">time</span><span class="o">+</span><span class="n">stwin</span><span class="p">,</span><span class="n">time</span><span class="o">+</span><span class="n">etwin</span><span class="p">,</span><span class="n">fix_overlaps</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
      <span class="n">ensout</span><span class="o">.</span><span class="n">member</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">d</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="c1"># above logic means this only happens if there is only one segment</span>
      <span class="c1"># in that case we can just use WindowData</span>
      <span class="n">d</span> <span class="o">=</span> <span class="n">WindowData</span><span class="p">(</span><span class="n">enstmp</span><span class="o">.</span><span class="n">member</span><span class="p">,</span><span class="n">time</span><span class="o">+</span><span class="n">stwin</span><span class="p">,</span><span class="n">time</span><span class="o">+</span><span class="n">etwin</span><span class="p">)</span>
      <span class="n">ensout</span><span class="o">.</span><span class="n">member</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">d</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">ensout</span>

<span class="c1"># This undefined function would read the arrival time data</span>
<span class="c1"># stored in some external form and return a list of python dict</span>
<span class="c1"># with the keys &#39;net&#39;, &#39;sta&#39;, and &#39;arrival_time&#39; defined.</span>
<span class="n">arrival_list</span> <span class="o">=</span> <span class="n">arrival2list</span><span class="p">(</span><span class="n">args</span><span class="p">)</span>
<span class="n">sort_clause</span><span class="o">=</span><span class="p">[(</span><span class="s2">&quot;chan&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="p">(</span><span class="s2">&quot;time&quot;</span><span class="p">,</span><span class="mi">1</span><span class="p">)]</span>
<span class="c1"># This creates a bag from arrival_list that we can pass to the</span>
<span class="c1"># reader for loading with the container_to_merge argument</span>
<span class="n">arrival_bag</span> <span class="o">=</span> <span class="n">dbg</span><span class="o">.</span><span class="n">from_sequence</span><span class="p">(</span><span class="n">arrival_list</span><span class="p">)</span>
<span class="n">window_start_time</span> <span class="o">=</span> <span class="o">-</span><span class="mf">100.0</span>   <span class="c1"># time of window start relative to arrival</span>
<span class="n">window_end_time</span> <span class="o">=</span> <span class="mf">300.0</span>   <span class="c1"># time of window end relative to arrival</span>
<span class="n">mybag</span> <span class="o">=</span> <span class="n">dbg</span><span class="o">.</span><span class="n">from_sequence</span><span class="p">(</span><span class="n">arrival_list</span><span class="p">)</span>
<span class="n">mybag</span> <span class="o">=</span> <span class="n">mybag</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">query_generator</span><span class="p">,</span><span class="n">window_start_time</span><span class="p">,</span><span class="n">window_end_time</span><span class="p">)</span>
<span class="n">qlist</span><span class="o">=</span><span class="n">mybag</span><span class="o">.</span><span class="n">compute</span><span class="p">()</span>
<span class="c1"># qlist now is a list of python dict defining queries.  These are</span>
<span class="c1"># passed to the parallel reader  to create a bag of ensemble objects.</span>
<span class="n">mybag</span> <span class="o">=</span> <span class="n">read_distributed_data</span><span class="p">(</span><span class="n">qlist</span><span class="p">,</span>
      <span class="n">dbc</span><span class="p">,</span>
      <span class="n">collection</span><span class="o">=</span><span class="s2">&quot;wf_miniseed&quot;</span><span class="p">,</span>
      <span class="n">sort_clause</span><span class="o">=</span><span class="n">sort_clause</span><span class="p">,</span>
      <span class="n">container_to_merge</span><span class="o">=</span><span class="n">arrival_bag</span><span class="p">,</span>
    <span class="p">)</span>
<span class="n">mybag</span> <span class="o">=</span> <span class="n">mybag</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">make_segments</span><span class="p">)</span>
<span class="c1"># note the output of this function, with default here, is a list of</span>
<span class="c1"># objectids of the saved waveforms</span>
<span class="n">out_ids</span> <span class="o">=</span> <span class="n">write_distributed_data</span><span class="p">(</span><span class="n">mybag</span><span class="p">,</span><span class="n">dbo</span><span class="p">,</span><span class="n">collection</span><span class="o">=</span><span class="s2">&quot;wf_TimeSeries&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>The above example is complicated a bit as it is an example of a parallel
job.  The parallel IO feature of this example are important as this
example could run very slowly as a serial job driven my millions of picks
that exists for the problem it simulates - an Earthscope TA
continuous data archive being accessed
to assemble a data set of several million waveform segments built from the
ANF catalog.  It may be helpful to expand on the main steps of this algorithm:</p>
<ol class="arabic simple">
<li><p>The first step assumes the existence of an undefined function with
the name <cite>arrival2list</cite>.   For the prototype example given it could
be driven by the CSS3.0 tables created by the Earthscope
Array Network Facility (ANF).  That data can currently be found
<a class="reference external" href="https://anf.ucsd.edu/tools/events/">here</a>.  The actual implementation
would need to select what picks to use and pull out a restricted set of
attributes from the CSS3.0 tables creating a large list of tuples
with each tuple containing:  [‚Äònet‚Äô, ‚Äòsta‚Äô, ‚Äòarrival_time‚Äô] values.
Note that step can be done in a couple of lines with the pandas
module but is omitted as that is not a unique solution.  (e.g. one
could also accomplish the same thing with a MongoDB database ‚Äòarrival‚Äô
collection with suitable content.)</p></li>
<li><p>The <cite>from_sequence</cite> method of dask bag creates a bag from a list.
In this case it becomes a bag of python dict containers.
The map call that follows
using the custom function defined earlier in the code box creates
a bag of python dictionaries that define queries to MongoDB.  What
the queries are designed to do is described in the docstring for that
function.</p></li>
<li><p>We call the compute method to actually create the list of queries
that will drive the reader.   That approach assumes the size of that
container is not overwhelming, which is likely a good assumption since
the individual dict containers are of the order of 100 bytes each.</p></li>
<li><p>The called to <cite>read_distributed_data</cite> defines the main parallel workflow.
In this mode it reads a (large) series of ensembles driven by the
input query list.  This usage creates a implicit parallel reader.
Each instance creates a <cite>TimeSeriesEnsemble</cite> with all channels
for a particular station that have waveforms that intersect with the
desired output time segment around the specified arrival time.
An important feature exploited in the reader here is that implemented
with the argument <cite>container_to_merge</cite>.  The docstrings give details
but the main functionality it provides is a way to do a one-to-one
mapping of a list of metadata loaded to the ensembles.  That feature
adds a major efficiency for large data sets compared to the alternative of
millions of MongoDB queries that one might consider to solve that problem.
This example also requires the <cite>sort_clause</cite> argument to assure the
queries return data in an order consistent with the requirements of the
<cite>make_segments</cite> function that does all main work here.</p></li>
<li><p>The map call following <cite>read_distributed_data</cite> calls the function
earlier that handles the slice and dice operation.  How that is done is
best gleaned fromt he docstring comments.</p></li>
<li><p>This example calls the parallel writer, <cite>write_distributed_data</cite>, to
save the results.</p></li>
</ol>
<p><em>Example 3:  Application of TimeIntervalReader.</em>
This example assumes we have a list of shot times from something like an
onshore-offshore experiment using airguns or a set set of land shots with
known shot times.  The script is serial, but is readily converted to
a parallel form using standard concepts described elsewhere in this user‚Äôs manual.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">mspasspy.db.DBClient</span><span class="w"> </span><span class="kn">import</span> <span class="n">DBClient</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">os</span>
<span class="n">dbclient</span><span class="o">=</span><span class="n">DBClient</span><span class="p">()</span>
<span class="n">db</span> <span class="o">=</span> <span class="n">dbclient</span><span class="o">.</span><span class="n">get_database</span><span class="p">(</span><span class="s2">&quot;my_continuous_dataset&quot;</span><span class="p">)</span>
<span class="n">wstime</span><span class="o">=</span><span class="mf">0.0</span>
<span class="n">wetime</span><span class="o">=</span><span class="mf">50.0</span>   <span class="c1"># cut 50 s listen windows</span>
<span class="k">with</span> <span class="n">fd</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">fopen</span><span class="p">(</span><span class="s2">&quot;shottimes.txt&quot;</span><span class="p">):</span>
  <span class="n">lines</span> <span class="o">=</span> <span class="n">fd</span><span class="o">.</span><span class="n">readlines</span><span class="p">()</span>
  <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">lines</span><span class="p">:</span>
    <span class="n">tslist</span> <span class="o">=</span> <span class="n">TimeIntervalReader</span><span class="p">(</span><span class="n">db</span><span class="p">,</span><span class="n">t</span><span class="o">+</span><span class="n">wstime</span><span class="p">,</span><span class="n">t</span><span class="o">+</span><span class="n">wetime</span><span class="p">,</span><span class="n">fix_overlaps</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">ts</span> <span class="ow">in</span> <span class="n">tslist</span><span class="p">:</span>
      <span class="n">db</span><span class="o">.</span><span class="n">save_data</span><span class="p">(</span><span class="n">ts</span><span class="p">)</span>   <span class="c1"># defaults to saving to wf_TimeSeries so omit data_tag</span>
</pre></div>
</div>
</section>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="processing_history_concepts.html" class="btn btn-neutral float-left" title="Processing History Concepts" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="schema_choices.html" class="btn btn-neutral float-right" title="What database schema should I use?" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2020-2021, Ian Wang.</p>
  </div>

   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>