<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>mspasspy.io.distributed &mdash; MsPASS 0.0.1 documentation</title>
      <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../../../_static/css/theme.css" type="text/css" />
      <link rel="stylesheet" href="../../../_static/copybutton.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script src="../../../_static/jquery.js?v=5d32c60e"></script>
        <script src="../../../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
        <script data-url_root="../../../" id="documentation_options" src="../../../_static/documentation_options.js?v=f6245a2f"></script>
        <script src="../../../_static/doctools.js?v=888ff710"></script>
        <script src="../../../_static/sphinx_highlight.js?v=4825356b"></script>
        <script src="../../../_static/clipboard.min.js?v=a7894cd8"></script>
        <script src="../../../_static/copybutton.js?v=f281be69"></script>
    <script src="../../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />  

  <style>
    .wy-nav-content { max-width: 1600px; }
  </style>

  
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../../index.html" class="icon icon-home">
            MsPASS
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
    
              <p class="caption" role="heading"><span class="caption-text">Getting Started</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../getting_started/run_mspass_with_docker.html">Run MsPASS with Docker</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../getting_started/deploy_mspass_with_docker_compose.html">Deploy MsPASS with Docker Compose</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../getting_started/deploy_mspass_on_HPC.html">Deploying MsPASS on an HPC cluster</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../getting_started/getting_started_overview.html">MsPASS Virtual Cluster Concepts</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">User Manual</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../user_manual/introduction.html">Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../user_manual/data_object_design_concepts.html">Data Object Design Concepts</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../user_manual/time_standard_constraints.html">Time Standard Constraints</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../user_manual/obspy_interface.html">Using ObsPy with MsPASS</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../user_manual/database_concepts.html">Database Concepts</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../user_manual/CRUD_operations.html">CRUD Operations in MsPASS</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../user_manual/importing_data.html">Importing Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../user_manual/handling_errors.html">Handling Errors</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../user_manual/data_editing.html">Data Editing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../user_manual/header_math.html">Header (Metadata) Math</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../user_manual/graphics.html">Graphics in MsPASS</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../user_manual/processing_history_concepts.html">Processing History Concepts</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../user_manual/parallel_processing.html">Parallel Processing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../user_manual/normalization.html">Normalization</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../user_manual/adapting_algorithms.html">Adapting an Existing Algorithm to MsPASS</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../user_manual/io.html">I/O in MsPASS</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Reference Manual</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../python_api/index.html">Python API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../cxx_api/index.html">C++ API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../mspass_schema/mspass_schema.html">MsPASS Schema</a></li>
</ul>

    <a href= "../../../genindex.html">Index</a>
  
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../index.html">MsPASS</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="../../index.html">Module code</a></li>
      <li class="breadcrumb-item active">mspasspy.io.distributed</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <h1>Source code for mspasspy.io.distributed</h1><div class="highlight"><pre>
<span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">Distributed Reader and Writer using DataFrame</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">io</span>
<span class="kn">import</span> <span class="nn">copy</span>
<span class="kn">import</span> <span class="nn">pathlib</span>
<span class="kn">import</span> <span class="nn">pickle</span>
<span class="kn">import</span> <span class="nn">struct</span>
<span class="kn">import</span> <span class="nn">urllib.request</span>
<span class="kn">from</span> <span class="nn">array</span> <span class="kn">import</span> <span class="n">array</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="kn">import</span> <span class="nn">gridfs</span>
<span class="kn">import</span> <span class="nn">pymongo</span>
<span class="kn">import</span> <span class="nn">pymongo.errors</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">obspy</span>
<span class="kn">from</span> <span class="nn">obspy.clients.fdsn</span> <span class="kn">import</span> <span class="n">Client</span>
<span class="kn">from</span> <span class="nn">obspy</span> <span class="kn">import</span> <span class="n">Inventory</span>
<span class="kn">from</span> <span class="nn">obspy</span> <span class="kn">import</span> <span class="n">UTCDateTime</span>
<span class="kn">import</span> <span class="nn">boto3</span><span class="o">,</span> <span class="nn">botocore</span>
<span class="kn">import</span> <span class="nn">json</span>
<span class="kn">import</span> <span class="nn">base64</span>
<span class="kn">import</span> <span class="nn">uuid</span>

<span class="kn">from</span> <span class="nn">mspasspy.db.database</span> <span class="kn">import</span> <span class="n">Database</span>
<span class="kn">from</span> <span class="nn">mspasspy.ccore.io</span> <span class="kn">import</span> <span class="n">_mseed_file_indexer</span><span class="p">,</span> <span class="n">_fwrite_to_file</span><span class="p">,</span> <span class="n">_fread_from_file</span>
<span class="kn">from</span> <span class="nn">mspasspy.util.converter</span> <span class="kn">import</span> <span class="n">Trace2TimeSeries</span><span class="p">,</span> <span class="n">Stream2Seismogram</span>

<span class="kn">from</span> <span class="nn">mspasspy.ccore.seismic</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">TimeSeries</span><span class="p">,</span>
    <span class="n">Seismogram</span><span class="p">,</span>
    <span class="n">_CoreSeismogram</span><span class="p">,</span>
    <span class="n">DoubleVector</span><span class="p">,</span>
    <span class="n">TimeSeriesEnsemble</span><span class="p">,</span>
    <span class="n">SeismogramEnsemble</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">mspasspy.ccore.utility</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">Metadata</span><span class="p">,</span>
    <span class="n">MsPASSError</span><span class="p">,</span>
    <span class="n">AtomicType</span><span class="p">,</span>
    <span class="n">ErrorSeverity</span><span class="p">,</span>
    <span class="n">dmatrix</span><span class="p">,</span>
    <span class="n">ProcessingHistory</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">mspasspy.db.collection</span> <span class="kn">import</span> <span class="n">Collection</span>
<span class="kn">from</span> <span class="nn">mspasspy.db.schema</span> <span class="kn">import</span> <span class="n">DatabaseSchema</span><span class="p">,</span> <span class="n">MetadataSchema</span>
<span class="kn">from</span> <span class="nn">mspasspy.util.converter</span> <span class="kn">import</span> <span class="n">Textfile2Dataframe</span>
<span class="kn">import</span> <span class="nn">dask.bag</span> <span class="k">as</span> <span class="nn">daskbag</span>
<span class="kn">from</span> <span class="nn">dask.dataframe.core</span> <span class="kn">import</span> <span class="n">DataFrame</span> <span class="k">as</span> <span class="n">daskDF</span>
<span class="kn">import</span> <span class="nn">dask</span>
<span class="kn">import</span> <span class="nn">pyspark</span>
<span class="kn">from</span> <span class="nn">pyspark.sql.dataframe</span> <span class="kn">import</span> <span class="n">DataFrame</span> <span class="k">as</span> <span class="n">sparkDF</span>
<span class="kn">import</span> <span class="nn">pyspark.sql</span>


<div class="viewcode-block" id="read_distributed_data"><a class="viewcode-back" href="../../../python_api/mspasspy.io.html#mspasspy.io.distributed.read_distributed_data">[docs]</a><span class="k">def</span> <span class="nf">read_distributed_data</span><span class="p">(</span>
    <span class="n">data</span><span class="p">,</span>
    <span class="n">cursor</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;promiscuous&quot;</span><span class="p">,</span>
    <span class="n">normalize</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">load_history</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">exclude_keys</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="nb">format</span><span class="o">=</span><span class="s2">&quot;dask&quot;</span><span class="p">,</span>
    <span class="n">npartitions</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">spark_context</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">data_tag</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">aws_access_key_id</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">aws_secret_access_key</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    This function should be used to read an entire dataset that is to be handled</span>
<span class="sd">    by subsequent parallel operations.  The function can be thought of as</span>
<span class="sd">    loading the entire data set into a parallel container (rdd for spark</span>
<span class="sd">    implementations or bag for a dask implementations).</span>

<span class="sd">    This function is to divide the process of reading into two parts:</span>
<span class="sd">    reading from database and reading from file, where where reading from database</span>
<span class="sd">    is done in sequence, and reading from file is done with dask/spark. The two parts</span>
<span class="sd">    are done in two functions: read_to_dataframe, and read_files.</span>

<span class="sd">    The data param can be database or dataframe. If it is database, the function will</span>
<span class="sd">    firstly read from the database sequentially, and save the metadata to a dataframe.</span>
<span class="sd">    Then we have the dataframe. Use the information in the dataframe to read from files</span>
<span class="sd">    using dask/spark distributedly, and generate the objects to the container. This step</span>
<span class="sd">    uses map in dask/spark to improve efficiency.</span>

<span class="sd">    All other arguments are options that change behavior as described below.</span>

<span class="sd">    :param data: the data to be read, can be database or dataframe.</span>
<span class="sd">    :type data: :class:`mspasspy.db.database.Database` or :class:`pandas.DataFrame`</span>
<span class="sd">    or :class:`dask.dataframe.core.DataFrame` or :class:`pyspark.sql.dataframe.DataFrame`</span>
<span class="sd">    :param cursor: mongodb cursor defining what &quot;the dataset&quot; is.  It would</span>
<span class="sd">      normally be the output of the find method with a workflow dependent</span>
<span class="sd">      query.</span>
<span class="sd">    :type cursor: :class:`pymongo.cursor.CursorType`</span>
<span class="sd">    :param mode: reading mode that controls how the function interacts with</span>
<span class="sd">      the schema definition for the data type.   Must be one of</span>
<span class="sd">      [&#39;promiscuous&#39;,&#39;cautious&#39;,&#39;pedantic&#39;].   See user&#39;s manual for a</span>
<span class="sd">      detailed description of what the modes mean.  Default is &#39;promiscuous&#39;</span>
<span class="sd">      which turns off all schema checks and loads all attributes defined for</span>
<span class="sd">      each object read.</span>
<span class="sd">    :type mode: :class:`str`</span>
<span class="sd">    :param normalize: list of collections that are to used for data</span>
<span class="sd">      normalization. (see User&#39;s manual and MongoDB documentation for</span>
<span class="sd">      details on this concept)  Briefly normalization means common</span>
<span class="sd">      metadata like source and receiver geometry are defined in separate</span>
<span class="sd">      smaller collections that are linked through this mechanism</span>
<span class="sd">      during reads. Default uses no normalization.</span>
<span class="sd">    :type normalize: a :class:`list` of :class:`str`</span>
<span class="sd">    :param load_history: boolean (True or False) switch used to enable or</span>
<span class="sd">      disable object level history mechanism.   When set True each datum</span>
<span class="sd">      will be tagged with its origin id that defines the leaf nodes of a</span>
<span class="sd">      history G-tree.  See the User&#39;s manual for additional details of this</span>
<span class="sd">      feature.  Default is False.</span>
<span class="sd">    :param exclude_keys: Sometimes it is helpful to remove one or more</span>
<span class="sd">      attributes stored in the database from the data&#39;s Metadata (header)</span>
<span class="sd">      so they will not cause problems in downstream processing.</span>
<span class="sd">    :type exclude_keys: a :class:`list` of :class:`str`</span>
<span class="sd">    :param format: Set the format of the parallel container to define the</span>
<span class="sd">      dataset.   Must be either &quot;spark&quot; or &quot;dask&quot; or the job will abort</span>
<span class="sd">      immediately with an exception</span>
<span class="sd">    :type format: :class:`str`</span>
<span class="sd">    :param spark_context: If using spark this argument is required.  Spark</span>
<span class="sd">      defines the concept of a &quot;context&quot; that is a global control object that</span>
<span class="sd">      manages schduling.  See online Spark documentation for details on</span>
<span class="sd">      this concept.</span>
<span class="sd">    :type spark_context: :class:`pyspark.SparkContext`</span>
<span class="sd">    :param npartitions: The number of desired partitions for Dask or the number</span>
<span class="sd">      of slices for Spark. By default Dask will use 100 and Spark will determine</span>
<span class="sd">      it automatically based on the cluster.</span>
<span class="sd">    :type npartitions: :class:`int`</span>
<span class="sd">    :param data_tag:  The definition of a dataset can become ambiguous</span>
<span class="sd">      when partially processed data are saved within a workflow.   A common</span>
<span class="sd">      example would be windowing long time blocks of data to shorter time</span>
<span class="sd">      windows around a particular seismic phase and saving the windowed data.</span>
<span class="sd">      The windowed data can be difficult to distinguish from the original</span>
<span class="sd">      with standard queries.  For this reason we make extensive use of &quot;tags&quot;</span>
<span class="sd">      for save and read operations to improve the efficiency and simplify</span>
<span class="sd">      read operations.   Default turns this off by setting the tag null (None).</span>
<span class="sd">    :type data_tag: :class:`str`</span>
<span class="sd">    :param aws_access_key_id: A part of the credentials to authenticate the user</span>
<span class="sd">    :param aws_secret_access_key: A part of the credentials to authenticate the user</span>
<span class="sd">    :return: container defining the parallel dataset.  A spark `RDD` if format</span>
<span class="sd">      is &quot;Spark&quot; and a dask &#39;bag&#39; if format is &quot;dask&quot;</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="p">(</span>
        <span class="nb">isinstance</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">)</span>
        <span class="ow">or</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">Database</span><span class="p">)</span>
        <span class="ow">or</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">sparkDF</span><span class="p">)</span>
        <span class="ow">or</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">daskDF</span><span class="p">)</span>
    <span class="p">):</span>
        <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">&quot;Only Database or DataFrame are supported&quot;</span><span class="p">)</span>
    <span class="n">db</span> <span class="o">=</span> <span class="n">data</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">Database</span><span class="p">):</span>
        <span class="c1">#  first read the metadata from database to a dataframe, and save to data</span>
        <span class="n">data</span> <span class="o">=</span> <span class="n">read_to_dataframe</span><span class="p">(</span>
            <span class="n">data</span><span class="p">,</span>
            <span class="n">cursor</span><span class="p">,</span>
            <span class="n">mode</span><span class="p">,</span>
            <span class="n">normalize</span><span class="p">,</span>
            <span class="n">load_history</span><span class="p">,</span>
            <span class="n">exclude_keys</span><span class="p">,</span>
            <span class="n">data_tag</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="c1"># convert dask dataframe to pandas dataframe</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">daskDF</span><span class="p">):</span>
        <span class="n">data</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">compute</span><span class="p">()</span>

    <span class="c1"># convert spark dataframe to spark dataframe</span>
    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">sparkDF</span><span class="p">):</span>
        <span class="n">data</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">toPandas</span><span class="p">()</span>

    <span class="c1"># now the type of data is a pandas dataframe</span>
    <span class="k">if</span> <span class="nb">format</span> <span class="o">==</span> <span class="s2">&quot;spark&quot;</span><span class="p">:</span>
        <span class="n">list_</span> <span class="o">=</span> <span class="n">spark_context</span><span class="o">.</span><span class="n">parallelize</span><span class="p">(</span>
            <span class="n">data</span><span class="o">.</span><span class="n">to_dict</span><span class="p">(</span><span class="s2">&quot;records&quot;</span><span class="p">),</span> <span class="n">numSlices</span><span class="o">=</span><span class="n">npartitions</span>
        <span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">list_</span> <span class="o">=</span> <span class="n">daskbag</span><span class="o">.</span><span class="n">from_sequence</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">to_dict</span><span class="p">(</span><span class="s2">&quot;records&quot;</span><span class="p">),</span> <span class="n">npartitions</span><span class="o">=</span><span class="n">npartitions</span><span class="p">)</span>

    <span class="c1"># list_ is a parallel container of dict</span>
    <span class="k">return</span> <span class="n">list_</span><span class="o">.</span><span class="n">map</span><span class="p">(</span>
        <span class="k">lambda</span> <span class="n">cur</span><span class="p">:</span> <span class="n">read_files</span><span class="p">(</span>
            <span class="n">Metadata</span><span class="p">(</span><span class="n">cur</span><span class="p">),</span>  <span class="c1"># convert dict to metadata</span>
            <span class="n">gridfs</span><span class="o">.</span><span class="n">GridFS</span><span class="p">(</span><span class="n">db</span><span class="p">)</span>
            <span class="k">if</span> <span class="p">(</span><span class="nb">isinstance</span><span class="p">(</span><span class="n">db</span><span class="p">,</span> <span class="n">Database</span><span class="p">)</span> <span class="ow">and</span> <span class="n">cur</span><span class="p">[</span><span class="s2">&quot;storage_mode&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;gridfs&quot;</span><span class="p">)</span>
            <span class="k">else</span> <span class="kc">None</span><span class="p">,</span>
            <span class="c1"># if storage mode is gridfs, pass a GridFS object, it can not be put in the dataframe because rdd/bag</span>
            <span class="c1"># can&#39;t pickle _thread.RLock objects</span>
            <span class="n">aws_access_key_id</span><span class="o">=</span><span class="n">aws_access_key_id</span><span class="p">,</span>
            <span class="n">aws_secret_access_key</span><span class="o">=</span><span class="n">aws_secret_access_key</span><span class="p">,</span>
        <span class="p">)</span>
    <span class="p">)</span>  <span class="c1"># does not compute or collect</span></div>


<div class="viewcode-block" id="read_to_dataframe"><a class="viewcode-back" href="../../../python_api/mspasspy.io.html#mspasspy.io.distributed.read_to_dataframe">[docs]</a><span class="k">def</span> <span class="nf">read_to_dataframe</span><span class="p">(</span>
    <span class="n">db</span><span class="p">,</span>
    <span class="n">cursor</span><span class="p">,</span>
    <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;promiscuous&quot;</span><span class="p">,</span>
    <span class="n">normalize</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">load_history</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">exclude_keys</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">data_tag</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">alg_name</span><span class="o">=</span><span class="s2">&quot;read_to_dataframe&quot;</span><span class="p">,</span>
    <span class="n">alg_id</span><span class="o">=</span><span class="s2">&quot;0&quot;</span><span class="p">,</span>
    <span class="n">define_as_raw</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">retrieve_history_record</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    This is the MsPASS reader for constructing metadata of Seismogram or TimeSeries</span>
<span class="sd">    objects from data managed with MondoDB through MsPASS. Firstly construct a list</span>
<span class="sd">    of objects using cursor. Then for each object, constrcut the metadata and add to</span>
<span class="sd">    the list. Finally convert the list to a dataframe. The return type is a dataframe</span>
<span class="sd">    of metadata. The logic of constructing metadata is same as Database.read_data().</span>

<span class="sd">    :param db: the database from which the data are to be read.</span>
<span class="sd">    :type db: :class:`mspasspy.db.database.Database`.</span>
<span class="sd">    :param object_id: MongoDB object id of the wf document to be constructed from</span>
<span class="sd">        data defined in the database.  The object id is guaranteed unique and provides</span>
<span class="sd">        a unique link to a unique document or nothing.   In the later case the</span>
<span class="sd">        function will return a None.</span>
<span class="sd">    :type cursor: :class:`pymongo.cursor.CursorType`</span>
<span class="sd">    :param mode: reading mode that controls how the function interacts with</span>
<span class="sd">        the schema definition for the data type.   Must be one of</span>
<span class="sd">        [&#39;promiscuous&#39;,&#39;cautious&#39;,&#39;pedantic&#39;].   See user&#39;s manual for a</span>
<span class="sd">        detailed description of what the modes mean.  Default is &#39;promiscuous&#39;</span>
<span class="sd">        which turns off all schema checks and loads all attributes defined for</span>
<span class="sd">        each object read.</span>
<span class="sd">    :type mode: :class:`str`</span>
<span class="sd">    :param normalize: list of collections that are to used for data</span>
<span class="sd">        normalization. (see User&#39;s manual and MongoDB documentation for</span>
<span class="sd">        details on this concept)  Briefly normalization means common</span>
<span class="sd">        metadata like source and receiver geometry are defined in separate</span>
<span class="sd">        smaller collections that are linked through this mechanism</span>
<span class="sd">        during reads. Default uses no normalization.</span>
<span class="sd">    :type normalize: a :class:`list` of :class:`str`</span>
<span class="sd">    :param load_history: boolean (True or False) switch used to enable or</span>
<span class="sd">        disable object level history mechanism.   When set True each datum</span>
<span class="sd">        will be tagged with its origin id that defines the leaf nodes of a</span>
<span class="sd">        history G-tree.  See the User&#39;s manual for additional details of this</span>
<span class="sd">        feature.  Default is False.</span>
<span class="sd">    :param exclude_keys: Sometimes it is helpful to remove one or more</span>
<span class="sd">        attributes stored in the database from the data&#39;s Metadata (header)</span>
<span class="sd">        so they will not cause problems in downstream processing.</span>
<span class="sd">    :type exclude_keys: a :class:`list` of :class:`str`</span>
<span class="sd">    :param collection:  Specify an alternate collection name to</span>
<span class="sd">        use for reading the data.  The default sets the collection name</span>
<span class="sd">        based on the data type and automatically loads the correct schema.</span>
<span class="sd">        The collection listed must be defined in the schema and satisfy</span>
<span class="sd">        the expectations of the reader.  This is an advanced option that</span>
<span class="sd">        is indended only to simplify extensions to the reader.</span>
<span class="sd">    :param data_tag:  The definition of a dataset can become ambiguous</span>
<span class="sd">        when partially processed data are saved within a workflow.   A common</span>
<span class="sd">        example would be windowing long time blocks of data to shorter time</span>
<span class="sd">        windows around a particular seismic phase and saving the windowed data.</span>
<span class="sd">        The windowed data can be difficult to distinguish from the original</span>
<span class="sd">        with standard queries.  For this reason we make extensive use of &quot;tags&quot;</span>
<span class="sd">        for save and read operations to improve the efficiency and simplify</span>
<span class="sd">        read operations.   Default turns this off by setting the tag null (None).</span>
<span class="sd">    :type data_tag: :class:`str`</span>
<span class="sd">    :param alg_name: alg_name is the name the func we are gonna save while preserving the history.</span>
<span class="sd">    :type alg_name: :class:`str`</span>
<span class="sd">    :param alg_id: alg_id is a unique id to record the usage of func while preserving the history.</span>
<span class="sd">    :type alg_id: :class:`bson.objectid.ObjectId`</span>
<span class="sd">    :param define_as_raw: a boolean control whether we would like to set_as_origin when loading processing history</span>
<span class="sd">    :type define_as_raw: :class:`bool`</span>
<span class="sd">    :param retrieve_history_record: a boolean control whether we would like to load processing history</span>
<span class="sd">    :type retrieve_history_record: :class:`bool`</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># first get the object list</span>
    <span class="n">obj_list</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">cursor</span><span class="p">)</span>

    <span class="n">collection</span> <span class="o">=</span> <span class="n">cursor</span><span class="o">.</span><span class="n">collection</span><span class="o">.</span><span class="n">name</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="n">wf_collection</span> <span class="o">=</span> <span class="n">db</span><span class="o">.</span><span class="n">database_schema</span><span class="o">.</span><span class="n">default_name</span><span class="p">(</span><span class="n">collection</span><span class="p">)</span>
    <span class="k">except</span> <span class="n">MsPASSError</span> <span class="k">as</span> <span class="n">err</span><span class="p">:</span>
        <span class="k">raise</span> <span class="n">MsPASSError</span><span class="p">(</span>
            <span class="s2">&quot;collection </span><span class="si">{}</span><span class="s2"> is not defined in database schema&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">collection</span><span class="p">),</span>
            <span class="s2">&quot;Invalid&quot;</span><span class="p">,</span>
        <span class="p">)</span> <span class="kn">from</span> <span class="nn">err</span>
    <span class="n">object_type</span> <span class="o">=</span> <span class="n">db</span><span class="o">.</span><span class="n">database_schema</span><span class="p">[</span><span class="n">wf_collection</span><span class="p">]</span><span class="o">.</span><span class="n">data_type</span><span class="p">()</span>

    <span class="k">if</span> <span class="n">object_type</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">[</span><span class="n">TimeSeries</span><span class="p">,</span> <span class="n">Seismogram</span><span class="p">]:</span>
        <span class="k">raise</span> <span class="n">MsPASSError</span><span class="p">(</span>
            <span class="s2">&quot;only TimeSeries and Seismogram are supported, but </span><span class="si">{}</span><span class="s2"> is requested. Please check the data_type of </span><span class="si">{}</span><span class="s2"> collection.&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                <span class="n">object_type</span><span class="p">,</span> <span class="n">wf_collection</span>
            <span class="p">),</span>
            <span class="s2">&quot;Fatal&quot;</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="k">if</span> <span class="n">mode</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;promiscuous&quot;</span><span class="p">,</span> <span class="s2">&quot;cautious&quot;</span><span class="p">,</span> <span class="s2">&quot;pedantic&quot;</span><span class="p">]:</span>
        <span class="k">raise</span> <span class="n">MsPASSError</span><span class="p">(</span>
            <span class="s2">&quot;only promiscuous, cautious and pedantic are supported, but </span><span class="si">{}</span><span class="s2"> is requested.&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                <span class="n">mode</span>
            <span class="p">),</span>
            <span class="s2">&quot;Fatal&quot;</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="k">if</span> <span class="n">normalize</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">normalize</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">if</span> <span class="n">exclude_keys</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">exclude_keys</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="c1"># This assumes the name of a metadata schema matches the data type it defines.</span>
    <span class="n">read_metadata_schema</span> <span class="o">=</span> <span class="n">db</span><span class="o">.</span><span class="n">metadata_schema</span><span class="p">[</span><span class="n">object_type</span><span class="o">.</span><span class="vm">__name__</span><span class="p">]</span>

    <span class="c1"># We temporarily swap the main collection defined by the metadata schema by</span>
    <span class="c1"># the wf_collection. This ensures the method works consistently for any</span>
    <span class="c1"># user-specified collection argument.</span>
    <span class="n">metadata_schema_collection</span> <span class="o">=</span> <span class="n">read_metadata_schema</span><span class="o">.</span><span class="n">collection</span><span class="p">(</span><span class="s2">&quot;_id&quot;</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">metadata_schema_collection</span> <span class="o">!=</span> <span class="n">wf_collection</span><span class="p">:</span>
        <span class="n">temp_metadata_schema</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">db</span><span class="o">.</span><span class="n">metadata_schema</span><span class="p">)</span>
        <span class="n">temp_metadata_schema</span><span class="p">[</span><span class="n">object_type</span><span class="o">.</span><span class="vm">__name__</span><span class="p">]</span><span class="o">.</span><span class="n">swap_collection</span><span class="p">(</span>
            <span class="n">metadata_schema_collection</span><span class="p">,</span> <span class="n">wf_collection</span><span class="p">,</span> <span class="n">db</span><span class="o">.</span><span class="n">database_schema</span>
        <span class="p">)</span>
        <span class="n">read_metadata_schema</span> <span class="o">=</span> <span class="n">temp_metadata_schema</span><span class="p">[</span><span class="n">object_type</span><span class="o">.</span><span class="vm">__name__</span><span class="p">]</span>

    <span class="c1"># find the corresponding document according to object id</span>
    <span class="n">col</span> <span class="o">=</span> <span class="n">db</span><span class="p">[</span><span class="n">wf_collection</span><span class="p">]</span>

    <span class="n">md_list</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="c1"># sequentially get all metadata for each object</span>
    <span class="k">for</span> <span class="n">object_id</span> <span class="ow">in</span> <span class="n">obj_list</span><span class="p">:</span>
        <span class="c1"># the same as read_data() in database.py</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">oid</span> <span class="o">=</span> <span class="n">object_id</span><span class="p">[</span><span class="s2">&quot;_id&quot;</span><span class="p">]</span>
        <span class="k">except</span><span class="p">:</span>
            <span class="n">oid</span> <span class="o">=</span> <span class="n">object_id</span>
        <span class="n">object_doc</span> <span class="o">=</span> <span class="n">db</span><span class="p">[</span><span class="n">wf_collection</span><span class="p">]</span><span class="o">.</span><span class="n">find_one</span><span class="p">({</span><span class="s2">&quot;_id&quot;</span><span class="p">:</span> <span class="n">oid</span><span class="p">})</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">object_doc</span><span class="p">:</span>
            <span class="n">md_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="kc">None</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">data_tag</span><span class="p">:</span>
            <span class="k">if</span> <span class="s2">&quot;data_tag&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">object_doc</span> <span class="ow">or</span> <span class="n">object_doc</span><span class="p">[</span><span class="s2">&quot;data_tag&quot;</span><span class="p">]</span> <span class="o">!=</span> <span class="n">data_tag</span><span class="p">:</span>
                <span class="n">md_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="kc">None</span><span class="p">)</span>

        <span class="c1"># 1. build metadata as dict</span>
        <span class="n">md</span> <span class="o">=</span> <span class="n">Metadata</span><span class="p">()</span>

        <span class="c1"># 1.1 read in the attributes from the document in the database</span>
        <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">object_doc</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">exclude_keys</span><span class="p">:</span>
                <span class="k">continue</span>
            <span class="k">if</span> <span class="n">mode</span> <span class="o">==</span> <span class="s2">&quot;promiscuous&quot;</span><span class="p">:</span>
                <span class="n">md</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">object_doc</span><span class="p">[</span><span class="n">k</span><span class="p">]</span>
                <span class="k">continue</span>
            <span class="c1"># FIXME: note that we do not check whether the attributes&#39; type in the database matches the schema&#39;s definition.</span>
            <span class="c1"># This may or may not be correct. Should test in practice and get user feedbacks.</span>
            <span class="k">if</span> <span class="n">read_metadata_schema</span><span class="o">.</span><span class="n">is_defined</span><span class="p">(</span><span class="n">k</span><span class="p">)</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">read_metadata_schema</span><span class="o">.</span><span class="n">is_alias</span><span class="p">(</span>
                <span class="n">k</span>
            <span class="p">):</span>
                <span class="n">md</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">object_doc</span><span class="p">[</span><span class="n">k</span><span class="p">]</span>

        <span class="c1"># 1.2 read the attributes in the metadata schema</span>
        <span class="c1"># col_dict is a hashmap used to store the normalized records by the normalized_id in object_doc</span>
        <span class="n">col_dict</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="c1"># log_error_msg is used to record all the elog entries generated during the reading process</span>
        <span class="c1"># After the mspass_object is created, we would post every elog entry with the messages in the log_error_msg.</span>
        <span class="n">log_error_msg</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">read_metadata_schema</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
            <span class="n">col</span> <span class="o">=</span> <span class="n">read_metadata_schema</span><span class="o">.</span><span class="n">collection</span><span class="p">(</span><span class="n">k</span><span class="p">)</span>
            <span class="c1"># explanation of the 4 conditions in the following if statement</span>
            <span class="c1"># 1.2.1. col is not None and is a normalized collection name</span>
            <span class="c1"># 1.2.2. normalized key id exists in the wf document</span>
            <span class="c1"># 1.2.3. k is not one of the exclude keys</span>
            <span class="c1"># 1.2.4. col is in the normalize list provided by user</span>
            <span class="k">if</span> <span class="p">(</span>
                <span class="n">col</span>
                <span class="ow">and</span> <span class="n">col</span> <span class="o">!=</span> <span class="n">wf_collection</span>
                <span class="ow">and</span> <span class="n">col</span> <span class="o">+</span> <span class="s2">&quot;_id&quot;</span> <span class="ow">in</span> <span class="n">object_doc</span>
                <span class="ow">and</span> <span class="n">k</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">exclude_keys</span>
                <span class="ow">and</span> <span class="n">col</span> <span class="ow">in</span> <span class="n">normalize</span>
            <span class="p">):</span>
                <span class="c1"># try to find the corresponding record in the normalized collection from the database</span>
                <span class="k">if</span> <span class="n">col</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">col_dict</span><span class="p">:</span>
                    <span class="n">col_dict</span><span class="p">[</span><span class="n">col</span><span class="p">]</span> <span class="o">=</span> <span class="n">db</span><span class="p">[</span><span class="n">col</span><span class="p">]</span><span class="o">.</span><span class="n">find_one</span><span class="p">({</span><span class="s2">&quot;_id&quot;</span><span class="p">:</span> <span class="n">object_doc</span><span class="p">[</span><span class="n">col</span> <span class="o">+</span> <span class="s2">&quot;_id&quot;</span><span class="p">]})</span>
                <span class="c1"># might unable to find the normalized document by the normalized_id in the object_doc</span>
                <span class="c1"># we skip reading this attribute</span>
                <span class="k">if</span> <span class="ow">not</span> <span class="n">col_dict</span><span class="p">[</span><span class="n">col</span><span class="p">]:</span>
                    <span class="k">continue</span>
                <span class="c1"># this attribute may be missing in the normalized record we retrieve above</span>
                <span class="c1"># in this case, we skip reading this attribute</span>
                <span class="c1"># however, if it is a required attribute for the normalized collection</span>
                <span class="c1"># we should post an elog entry to the associated wf object created after.</span>
                <span class="n">unique_k</span> <span class="o">=</span> <span class="n">db</span><span class="o">.</span><span class="n">database_schema</span><span class="p">[</span><span class="n">col</span><span class="p">]</span><span class="o">.</span><span class="n">unique_name</span><span class="p">(</span><span class="n">k</span><span class="p">)</span>
                <span class="k">if</span> <span class="ow">not</span> <span class="n">unique_k</span> <span class="ow">in</span> <span class="n">col_dict</span><span class="p">[</span><span class="n">col</span><span class="p">]:</span>
                    <span class="k">if</span> <span class="n">db</span><span class="o">.</span><span class="n">database_schema</span><span class="p">[</span><span class="n">col</span><span class="p">]</span><span class="o">.</span><span class="n">is_required</span><span class="p">(</span><span class="n">unique_k</span><span class="p">):</span>
                        <span class="n">log_error_msg</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                            <span class="s2">&quot;Attribute </span><span class="si">{}</span><span class="s2"> is required in collection </span><span class="si">{}</span><span class="s2">, but is missing in the document with id=</span><span class="si">{}</span><span class="s2">.&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                                <span class="n">unique_k</span><span class="p">,</span> <span class="n">col</span><span class="p">,</span> <span class="n">object_doc</span><span class="p">[</span><span class="n">col</span> <span class="o">+</span> <span class="s2">&quot;_id&quot;</span><span class="p">]</span>
                            <span class="p">)</span>
                        <span class="p">)</span>
                    <span class="k">continue</span>
                <span class="n">md</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">col_dict</span><span class="p">[</span><span class="n">col</span><span class="p">][</span><span class="n">unique_k</span><span class="p">]</span>

        <span class="c1"># 1.3 schema check normalized data according to the read mode</span>
        <span class="n">is_dead</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="n">fatal_keys</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">if</span> <span class="n">mode</span> <span class="o">==</span> <span class="s2">&quot;cautious&quot;</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">md</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">read_metadata_schema</span><span class="o">.</span><span class="n">is_defined</span><span class="p">(</span><span class="n">k</span><span class="p">):</span>
                    <span class="n">col</span> <span class="o">=</span> <span class="n">read_metadata_schema</span><span class="o">.</span><span class="n">collection</span><span class="p">(</span><span class="n">k</span><span class="p">)</span>
                    <span class="n">unique_key</span> <span class="o">=</span> <span class="n">db</span><span class="o">.</span><span class="n">database_schema</span><span class="p">[</span><span class="n">col</span><span class="p">]</span><span class="o">.</span><span class="n">unique_name</span><span class="p">(</span><span class="n">k</span><span class="p">)</span>
                    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">md</span><span class="p">[</span><span class="n">k</span><span class="p">],</span> <span class="n">read_metadata_schema</span><span class="o">.</span><span class="n">type</span><span class="p">(</span><span class="n">k</span><span class="p">)):</span>
                        <span class="c1"># try to convert the mismatch attribute</span>
                        <span class="k">try</span><span class="p">:</span>
                            <span class="c1"># convert the attribute to the correct type</span>
                            <span class="n">md</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">read_metadata_schema</span><span class="o">.</span><span class="n">type</span><span class="p">(</span><span class="n">k</span><span class="p">)(</span><span class="n">md</span><span class="p">[</span><span class="n">k</span><span class="p">])</span>
                        <span class="k">except</span><span class="p">:</span>
                            <span class="k">if</span> <span class="n">db</span><span class="o">.</span><span class="n">database_schema</span><span class="p">[</span><span class="n">col</span><span class="p">]</span><span class="o">.</span><span class="n">is_required</span><span class="p">(</span><span class="n">unique_key</span><span class="p">):</span>
                                <span class="n">fatal_keys</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">k</span><span class="p">)</span>
                                <span class="n">is_dead</span> <span class="o">=</span> <span class="kc">True</span>
                                <span class="n">log_error_msg</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                                    <span class="s2">&quot;cautious mode: Required attribute </span><span class="si">{}</span><span class="s2"> has type </span><span class="si">{}</span><span class="s2">, forbidden by definition and unable to convert&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                                        <span class="n">k</span><span class="p">,</span> <span class="nb">type</span><span class="p">(</span><span class="n">md</span><span class="p">[</span><span class="n">k</span><span class="p">])</span>
                                    <span class="p">)</span>
                                <span class="p">)</span>

        <span class="k">elif</span> <span class="n">mode</span> <span class="o">==</span> <span class="s2">&quot;pedantic&quot;</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">md</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">read_metadata_schema</span><span class="o">.</span><span class="n">is_defined</span><span class="p">(</span><span class="n">k</span><span class="p">):</span>
                    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">md</span><span class="p">[</span><span class="n">k</span><span class="p">],</span> <span class="n">read_metadata_schema</span><span class="o">.</span><span class="n">type</span><span class="p">(</span><span class="n">k</span><span class="p">)):</span>
                        <span class="n">fatal_keys</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">k</span><span class="p">)</span>
                        <span class="n">is_dead</span> <span class="o">=</span> <span class="kc">True</span>
                        <span class="n">log_error_msg</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                            <span class="s2">&quot;pedantic mode: </span><span class="si">{}</span><span class="s2"> has type </span><span class="si">{}</span><span class="s2">, forbidden by definition&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                                <span class="n">k</span><span class="p">,</span> <span class="nb">type</span><span class="p">(</span><span class="n">md</span><span class="p">[</span><span class="n">k</span><span class="p">])</span>
                            <span class="p">)</span>
                        <span class="p">)</span>

        <span class="c1"># 1.4 create a mspass object by passing MetaData</span>
        <span class="c1"># if not changing the fatal key values, runtime error in construct a mspass object</span>
        <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">fatal_keys</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">read_metadata_schema</span><span class="o">.</span><span class="n">type</span><span class="p">(</span><span class="n">k</span><span class="p">)</span> <span class="ow">is</span> <span class="nb">str</span><span class="p">:</span>
                <span class="n">md</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span>
            <span class="k">elif</span> <span class="n">read_metadata_schema</span><span class="o">.</span><span class="n">type</span><span class="p">(</span><span class="n">k</span><span class="p">)</span> <span class="ow">is</span> <span class="nb">int</span><span class="p">:</span>
                <span class="n">md</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="k">elif</span> <span class="n">read_metadata_schema</span><span class="o">.</span><span class="n">type</span><span class="p">(</span><span class="n">k</span><span class="p">)</span> <span class="ow">is</span> <span class="nb">float</span><span class="p">:</span>
                <span class="n">md</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="mf">0.0</span>
            <span class="k">elif</span> <span class="n">read_metadata_schema</span><span class="o">.</span><span class="n">type</span><span class="p">(</span><span class="n">k</span><span class="p">)</span> <span class="ow">is</span> <span class="nb">bool</span><span class="p">:</span>
                <span class="n">md</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="kc">False</span>
            <span class="k">elif</span> <span class="n">read_metadata_schema</span><span class="o">.</span><span class="n">type</span><span class="p">(</span><span class="n">k</span><span class="p">)</span> <span class="ow">is</span> <span class="nb">dict</span><span class="p">:</span>
                <span class="n">md</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="p">{}</span>
            <span class="k">elif</span> <span class="n">read_metadata_schema</span><span class="o">.</span><span class="n">type</span><span class="p">(</span><span class="n">k</span><span class="p">)</span> <span class="ow">is</span> <span class="nb">list</span><span class="p">:</span>
                <span class="n">md</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="k">elif</span> <span class="n">read_metadata_schema</span><span class="o">.</span><span class="n">type</span><span class="p">(</span><span class="n">k</span><span class="p">)</span> <span class="ow">is</span> <span class="nb">bytes</span><span class="p">:</span>
                <span class="n">md</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="sa">b</span><span class="s2">&quot;</span><span class="se">\x00</span><span class="s2">&quot;</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">md</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="c1"># init a ProcessingHistory to store history</span>
        <span class="n">processing_history_record</span> <span class="o">=</span> <span class="n">ProcessingHistory</span><span class="p">()</span>
        <span class="c1"># load the history in database</span>
        <span class="n">elog_col_name</span> <span class="o">=</span> <span class="n">db</span><span class="o">.</span><span class="n">database_schema</span><span class="o">.</span><span class="n">default_name</span><span class="p">(</span><span class="s2">&quot;elog&quot;</span><span class="p">)</span>
        <span class="n">elog_id_name</span> <span class="o">=</span> <span class="n">elog_col_name</span> <span class="o">+</span> <span class="s2">&quot;_id&quot;</span>
        <span class="k">if</span> <span class="n">elog_id_name</span> <span class="ow">in</span> <span class="n">object_doc</span><span class="p">:</span>
            <span class="n">elog_id</span> <span class="o">=</span> <span class="n">object_doc</span><span class="p">[</span><span class="n">elog_id_name</span><span class="p">]</span>
            <span class="n">elog_doc</span> <span class="o">=</span> <span class="n">db</span><span class="p">[</span><span class="n">elog_col_name</span><span class="p">]</span><span class="o">.</span><span class="n">find_one</span><span class="p">({</span><span class="s2">&quot;_id&quot;</span><span class="p">:</span> <span class="n">elog_id</span><span class="p">})</span>
            <span class="k">for</span> <span class="n">log</span> <span class="ow">in</span> <span class="n">elog_doc</span><span class="p">[</span><span class="s2">&quot;logdata&quot;</span><span class="p">]:</span>
                <span class="n">me</span> <span class="o">=</span> <span class="n">MsPASSError</span><span class="p">(</span><span class="n">log</span><span class="p">[</span><span class="s2">&quot;error_message&quot;</span><span class="p">],</span> <span class="n">log</span><span class="p">[</span><span class="s2">&quot;badness&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;.&quot;</span><span class="p">)[</span><span class="mi">1</span><span class="p">])</span>
                <span class="n">processing_history_record</span><span class="o">.</span><span class="n">elog</span><span class="o">.</span><span class="n">log_error</span><span class="p">(</span>
                    <span class="n">log</span><span class="p">[</span><span class="s2">&quot;algorithm&quot;</span><span class="p">],</span> <span class="n">log</span><span class="p">[</span><span class="s2">&quot;error_message&quot;</span><span class="p">],</span> <span class="n">me</span><span class="o">.</span><span class="n">severity</span>
                <span class="p">)</span>

        <span class="c1"># not continue step 2 &amp; 3 if the mspass object is dead</span>
        <span class="k">if</span> <span class="n">is_dead</span><span class="p">:</span>
            <span class="n">md</span><span class="p">[</span><span class="s2">&quot;is_dead&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">True</span>  <span class="c1"># mspass_object.kill()</span>
            <span class="k">for</span> <span class="n">msg</span> <span class="ow">in</span> <span class="n">log_error_msg</span><span class="p">:</span>
                <span class="n">processing_history_record</span><span class="o">.</span><span class="n">elog</span><span class="o">.</span><span class="n">log_error</span><span class="p">(</span>
                    <span class="s2">&quot;read_data&quot;</span><span class="p">,</span> <span class="n">msg</span><span class="p">,</span> <span class="n">ErrorSeverity</span><span class="o">.</span><span class="n">Invalid</span>
                <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">md</span><span class="p">[</span><span class="s2">&quot;is_dead&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">False</span>  <span class="c1"># mspass_object.live = True</span>

            <span class="c1"># 3.load history</span>
            <span class="k">if</span> <span class="n">load_history</span><span class="p">:</span>
                <span class="n">history_obj_id_name</span> <span class="o">=</span> <span class="p">(</span>
                    <span class="n">db</span><span class="o">.</span><span class="n">database_schema</span><span class="o">.</span><span class="n">default_name</span><span class="p">(</span><span class="s2">&quot;history_object&quot;</span><span class="p">)</span> <span class="o">+</span> <span class="s2">&quot;_id&quot;</span>
                <span class="p">)</span>
                <span class="k">if</span> <span class="n">history_obj_id_name</span> <span class="ow">in</span> <span class="n">object_doc</span><span class="p">:</span>
                    <span class="c1"># Load (in place) the processing history into h.</span>
                    <span class="n">history_object_id</span> <span class="o">=</span> <span class="n">object_doc</span><span class="p">[</span><span class="n">history_obj_id_name</span><span class="p">]</span>
                    <span class="c1"># get the atomic type of the mspass object</span>
                    <span class="k">if</span> <span class="n">object_type</span> <span class="ow">is</span> <span class="n">TimeSeries</span><span class="p">:</span>
                        <span class="n">atomic_type</span> <span class="o">=</span> <span class="n">AtomicType</span><span class="o">.</span><span class="n">TIMESERIES</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="n">atomic_type</span> <span class="o">=</span> <span class="n">AtomicType</span><span class="o">.</span><span class="n">SEISMOGRAM</span>
                    <span class="k">if</span> <span class="ow">not</span> <span class="n">collection</span><span class="p">:</span>
                        <span class="n">collection</span> <span class="o">=</span> <span class="n">db</span><span class="o">.</span><span class="n">database_schema</span><span class="o">.</span><span class="n">default_name</span><span class="p">(</span><span class="s2">&quot;history_object&quot;</span><span class="p">)</span>
                    <span class="c1"># load history if set True</span>
                    <span class="n">res</span> <span class="o">=</span> <span class="n">db</span><span class="p">[</span><span class="n">collection</span><span class="p">]</span><span class="o">.</span><span class="n">find_one</span><span class="p">({</span><span class="s2">&quot;_id&quot;</span><span class="p">:</span> <span class="n">history_object_id</span><span class="p">})</span>
                    <span class="c1"># retrieve_history_record</span>
                    <span class="k">if</span> <span class="n">retrieve_history_record</span><span class="p">:</span>
                        <span class="n">processing_history_record</span> <span class="o">=</span> <span class="n">pickle</span><span class="o">.</span><span class="n">loads</span><span class="p">(</span>
                            <span class="n">res</span><span class="p">[</span><span class="s2">&quot;processing_history&quot;</span><span class="p">]</span>
                        <span class="p">)</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="c1"># set the associated history_object_id as the uuid of the origin</span>
                        <span class="k">if</span> <span class="ow">not</span> <span class="n">alg_name</span><span class="p">:</span>
                            <span class="n">alg_name</span> <span class="o">=</span> <span class="s2">&quot;0&quot;</span>
                        <span class="k">if</span> <span class="ow">not</span> <span class="n">alg_id</span><span class="p">:</span>
                            <span class="n">alg_id</span> <span class="o">=</span> <span class="s2">&quot;0&quot;</span>
                        <span class="n">processing_history_record</span><span class="o">.</span><span class="n">set_as_origin</span><span class="p">(</span>
                            <span class="n">alg_name</span><span class="p">,</span>
                            <span class="n">alg_id</span><span class="p">,</span>
                            <span class="n">history_object_id</span><span class="p">,</span>
                            <span class="n">atomic_type</span><span class="p">,</span>
                            <span class="n">define_as_raw</span><span class="p">,</span>
                        <span class="p">)</span>

            <span class="n">md</span><span class="o">.</span><span class="n">clear_modified</span><span class="p">()</span>

            <span class="c1"># 4.post complaint elog entries if any</span>
            <span class="k">for</span> <span class="n">msg</span> <span class="ow">in</span> <span class="n">log_error_msg</span><span class="p">:</span>
                <span class="n">processing_history_record</span><span class="o">.</span><span class="n">elog</span><span class="o">.</span><span class="n">log_error</span><span class="p">(</span>
                    <span class="s2">&quot;read_data&quot;</span><span class="p">,</span> <span class="n">msg</span><span class="p">,</span> <span class="n">ErrorSeverity</span><span class="o">.</span><span class="n">Complaint</span>
                <span class="p">)</span>

        <span class="c1"># save additional params to metadata</span>
        <span class="n">md</span><span class="p">[</span><span class="s2">&quot;history&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">processing_history_record</span>
        <span class="k">if</span> <span class="n">object_type</span> <span class="ow">is</span> <span class="n">TimeSeries</span><span class="p">:</span>
            <span class="n">md</span><span class="p">[</span><span class="s2">&quot;object_type&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;TimeSeries&quot;</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">md</span><span class="p">[</span><span class="s2">&quot;object_type&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;Seismogram&quot;</span>
        <span class="n">md</span><span class="p">[</span><span class="s2">&quot;storage_mode&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">object_doc</span><span class="p">[</span><span class="s2">&quot;storage_mode&quot;</span><span class="p">]</span>
        <span class="c1"># if md[&quot;storage_mode&quot;] == &quot;gridfs&quot;:</span>
        <span class="c1">#    md[&quot;gfsh&quot;] = gridfs.GridFS(db)</span>
        <span class="n">md</span><span class="p">[</span><span class="s2">&quot;dir&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">object_doc</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;dir&quot;</span><span class="p">)</span>
        <span class="n">md</span><span class="p">[</span><span class="s2">&quot;dfile&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">object_doc</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;dfile&quot;</span><span class="p">)</span>
        <span class="n">md</span><span class="p">[</span><span class="s2">&quot;foff&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">object_doc</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;foff&quot;</span><span class="p">)</span>
        <span class="n">md</span><span class="p">[</span><span class="s2">&quot;nbytes&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">object_doc</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;nbytes&quot;</span><span class="p">)</span>
        <span class="n">md</span><span class="p">[</span><span class="s2">&quot;format&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">object_doc</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;format&quot;</span><span class="p">)</span>
        <span class="n">md</span><span class="p">[</span><span class="s2">&quot;gridfs_id&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">object_doc</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;gridfs_id&quot;</span><span class="p">)</span>
        <span class="n">md</span><span class="p">[</span><span class="s2">&quot;url&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">object_doc</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;url&quot;</span><span class="p">)</span>

        <span class="c1"># add metadata for current object to metadata list</span>
        <span class="n">md_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">md</span><span class="p">)</span>

    <span class="c1"># convert the metadata list to a dataframe</span>
    <span class="k">return</span> <span class="n">pd</span><span class="o">.</span><span class="n">json_normalize</span><span class="p">(</span><span class="nb">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">cur</span><span class="p">:</span> <span class="n">cur</span><span class="o">.</span><span class="n">todict</span><span class="p">(),</span> <span class="n">md_list</span><span class="p">))</span></div>


<div class="viewcode-block" id="read_files"><a class="viewcode-back" href="../../../python_api/mspasspy.io.html#mspasspy.io.distributed.read_files">[docs]</a><span class="k">def</span> <span class="nf">read_files</span><span class="p">(</span>
    <span class="n">md</span><span class="p">,</span>
    <span class="n">gfsh</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">aws_access_key_id</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">aws_secret_access_key</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    This is the reader for constructing the object from storage. Firstly construct the object,</span>
<span class="sd">    either TimeSeries or Seismogram, then read the stored data from a file or in gridfs and</span>
<span class="sd">    loads it into the mspasspy object. It will also load history in metadata. If the object is</span>
<span class="sd">    marked dead, it will not read and return an empty object with history. The logic of reading</span>
<span class="sd">    is same as Database.read_data().</span>

<span class="sd">    :param md: the metadata for the object to be read.</span>
<span class="sd">    :type md: :class:`mspasspy.ccore.utility.Metadata`.</span>
<span class="sd">    :param gfsh: GridFS object</span>
<span class="sd">    :type gfsh: :class:`gridfs.GridFS`</span>
<span class="sd">    :param aws_access_key_id: A part of the credentials to authenticate the user</span>
<span class="sd">    :param aws_secret_access_key: A part of the credentials to authenticate the user</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="c1"># Note a CRITICAL feature of the Metadata constructors</span>
        <span class="c1"># for both of these objects is that they allocate the</span>
        <span class="c1"># buffer for the sample data and initialize it to zero.</span>
        <span class="c1"># This allows sample data readers to load the buffer without</span>
        <span class="c1"># having to handle memory management.</span>
        <span class="k">if</span> <span class="n">md</span><span class="p">[</span><span class="s2">&quot;object_type&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;TimeSeries&quot;</span><span class="p">:</span>
            <span class="n">mspass_object</span> <span class="o">=</span> <span class="n">TimeSeries</span><span class="p">(</span><span class="n">md</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># api mismatch here.  This ccore Seismogram constructor</span>
            <span class="c1"># had an ancestor that had an option to read data here.</span>
            <span class="c1"># we never do that here</span>
            <span class="n">mspass_object</span> <span class="o">=</span> <span class="n">Seismogram</span><span class="p">(</span><span class="n">md</span><span class="p">,</span> <span class="kc">False</span><span class="p">)</span>
    <span class="k">except</span> <span class="n">MsPASSError</span> <span class="k">as</span> <span class="n">merr</span><span class="p">:</span>
        <span class="c1"># if the constructor fails mspass_object will be invalid</span>
        <span class="c1"># To preserve the error we have to create a shell to hold the error</span>
        <span class="k">if</span> <span class="n">md</span><span class="p">[</span><span class="s2">&quot;object_type&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;TimeSeries&quot;</span><span class="p">:</span>
            <span class="n">mspass_object</span> <span class="o">=</span> <span class="n">TimeSeries</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">mspass_object</span> <span class="o">=</span> <span class="n">Seismogram</span><span class="p">()</span>
        <span class="c1"># Default constructors leaves result marked dead so below should work</span>
        <span class="n">mspass_object</span><span class="o">.</span><span class="n">elog</span><span class="o">.</span><span class="n">log_error</span><span class="p">(</span><span class="n">merr</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">mspass_object</span>

    <span class="c1"># load history</span>
    <span class="k">if</span> <span class="s2">&quot;history&quot;</span> <span class="ow">in</span> <span class="n">md</span><span class="p">:</span>
        <span class="n">mspass_object</span><span class="o">.</span><span class="n">load_history</span><span class="p">(</span><span class="n">md</span><span class="p">[</span><span class="s2">&quot;history&quot;</span><span class="p">])</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="n">md</span><span class="p">[</span><span class="s2">&quot;is_dead&quot;</span><span class="p">]:</span>
        <span class="n">mspass_object</span><span class="o">.</span><span class="n">set_live</span><span class="p">()</span>
        <span class="c1"># 2.load data from different modes</span>
        <span class="n">storage_mode</span> <span class="o">=</span> <span class="n">md</span><span class="p">[</span><span class="s2">&quot;storage_mode&quot;</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">storage_mode</span> <span class="o">==</span> <span class="s2">&quot;file&quot;</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">md</span><span class="o">.</span><span class="n">is_defined</span><span class="p">(</span><span class="s2">&quot;format&quot;</span><span class="p">):</span>  <span class="c1"># &quot;format&quot; in object_doc:</span>
                <span class="n">Database</span><span class="o">.</span><span class="n">_read_data_from_dfile</span><span class="p">(</span>
                    <span class="n">mspass_object</span><span class="p">,</span>
                    <span class="n">md</span><span class="p">[</span><span class="s2">&quot;dir&quot;</span><span class="p">],</span>
                    <span class="n">md</span><span class="p">[</span><span class="s2">&quot;dfile&quot;</span><span class="p">],</span>
                    <span class="n">md</span><span class="p">[</span><span class="s2">&quot;foff&quot;</span><span class="p">],</span>
                    <span class="n">nbytes</span><span class="o">=</span><span class="n">md</span><span class="p">[</span><span class="s2">&quot;nbytes&quot;</span><span class="p">],</span>
                    <span class="nb">format</span><span class="o">=</span><span class="n">md</span><span class="p">[</span><span class="s2">&quot;format&quot;</span><span class="p">],</span>
                <span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">Database</span><span class="o">.</span><span class="n">_read_data_from_dfile</span><span class="p">(</span>
                    <span class="n">mspass_object</span><span class="p">,</span>
                    <span class="n">md</span><span class="p">[</span><span class="s2">&quot;dir&quot;</span><span class="p">],</span>
                    <span class="n">md</span><span class="p">[</span><span class="s2">&quot;dfile&quot;</span><span class="p">],</span>
                    <span class="n">md</span><span class="p">[</span><span class="s2">&quot;foff&quot;</span><span class="p">],</span>
                <span class="p">)</span>
        <span class="k">elif</span> <span class="n">storage_mode</span> <span class="o">==</span> <span class="s2">&quot;gridfs&quot;</span><span class="p">:</span>
            <span class="c1"># tried to store GridFS object in metadata here, but GridFS object in Pandas.DataFrame</span>
            <span class="c1"># can not be converted to RDD or daskbag, it will throw a TypeError: can&#39;t pickle _thread.RLock objects.</span>
            <span class="c1"># If the storage mode is gridfs, we have to use the database.</span>
            <span class="c1"># raise TypeError(&quot;gridfs storage mode are not supported in distributed read&quot;)</span>
            <span class="k">if</span> <span class="n">gfsh</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">_read_data_from_gridfs</span><span class="p">(</span><span class="n">gfsh</span><span class="p">,</span> <span class="n">mspass_object</span><span class="p">,</span> <span class="n">md</span><span class="p">[</span><span class="s2">&quot;gridfs_id&quot;</span><span class="p">])</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
                    <span class="s2">&quot;To use gridfs storage mode, must provide database rather than dataframe&quot;</span>
                <span class="p">)</span>
        <span class="k">elif</span> <span class="n">storage_mode</span> <span class="o">==</span> <span class="s2">&quot;url&quot;</span><span class="p">:</span>
            <span class="n">Database</span><span class="o">.</span><span class="n">_read_data_from_url</span><span class="p">(</span>
                <span class="n">mspass_object</span><span class="p">,</span>
                <span class="n">md</span><span class="p">[</span><span class="s2">&quot;url&quot;</span><span class="p">],</span>
                <span class="nb">format</span><span class="o">=</span><span class="n">md</span><span class="p">[</span><span class="s2">&quot;format&quot;</span><span class="p">],</span>
            <span class="p">)</span>
        <span class="k">elif</span> <span class="n">storage_mode</span> <span class="o">==</span> <span class="s2">&quot;s3_continuous&quot;</span><span class="p">:</span>
            <span class="n">Database</span><span class="o">.</span><span class="n">_read_data_from_s3_continuous</span><span class="p">(</span>
                <span class="n">mspass_object</span><span class="p">,</span> <span class="n">aws_access_key_id</span><span class="p">,</span> <span class="n">aws_secret_access_key</span>
            <span class="p">)</span>
        <span class="k">elif</span> <span class="n">storage_mode</span> <span class="o">==</span> <span class="s2">&quot;s3_lambda&quot;</span><span class="p">:</span>
            <span class="n">Database</span><span class="o">.</span><span class="n">_read_data_from_s3_lambda</span><span class="p">(</span>
                <span class="n">mspass_object</span><span class="p">,</span> <span class="n">aws_access_key_id</span><span class="p">,</span> <span class="n">aws_secret_access_key</span>
            <span class="p">)</span>
        <span class="k">elif</span> <span class="n">storage_mode</span> <span class="o">==</span> <span class="s2">&quot;fdsn&quot;</span><span class="p">:</span>
            <span class="n">Database</span><span class="o">.</span><span class="n">_read_data_from_fdsn</span><span class="p">(</span><span class="n">mspass_object</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>  <span class="c1"># add another parameter</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">&quot;Unknown storage mode: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">storage_mode</span><span class="p">))</span>

    <span class="c1"># after loading history, the history in metadata can be removed</span>
    <span class="n">mspass_object</span><span class="o">.</span><span class="n">erase</span><span class="p">(</span><span class="s2">&quot;history&quot;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">mspass_object</span></div>


<span class="k">def</span> <span class="nf">_read_data_from_gridfs</span><span class="p">(</span><span class="n">gfsh</span><span class="p">,</span> <span class="n">mspass_object</span><span class="p">,</span> <span class="n">gridfs_id</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Read data stored in gridfs and load it into a mspasspy object. This is similar</span>
<span class="sd">    to database._read_data_from_gridfs(), but here we have gfsh as a parameter to</span>
<span class="sd">    avoid using database object.</span>

<span class="sd">    :param gfsh: GridFS object</span>
<span class="sd">    :type gfsh: :class:`gridfs.GridFS`</span>
<span class="sd">    :param mspass_object: the target object.</span>
<span class="sd">    :type mspass_object: either :class:`mspasspy.ccore.seismic.TimeSeries` or :class:`mspasspy.ccore.seismic.Seismogram`</span>
<span class="sd">    :param gridfs_id: the object id of the data stored in gridfs.</span>
<span class="sd">    :type gridfs_id: :class:`bson.objectid.ObjectId`</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">fh</span> <span class="o">=</span> <span class="n">gfsh</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">file_id</span><span class="o">=</span><span class="n">gridfs_id</span><span class="p">)</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">mspass_object</span><span class="p">,</span> <span class="n">TimeSeries</span><span class="p">):</span>
        <span class="c1"># fh.seek(16)</span>
        <span class="n">float_array</span> <span class="o">=</span> <span class="n">array</span><span class="p">(</span><span class="s2">&quot;d&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">mspass_object</span><span class="o">.</span><span class="n">is_defined</span><span class="p">(</span><span class="s2">&quot;npts&quot;</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">KeyError</span><span class="p">(</span><span class="s2">&quot;npts is not defined&quot;</span><span class="p">)</span>
        <span class="n">float_array</span><span class="o">.</span><span class="n">frombytes</span><span class="p">(</span><span class="n">fh</span><span class="o">.</span><span class="n">read</span><span class="p">(</span><span class="n">mspass_object</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;npts&quot;</span><span class="p">)</span> <span class="o">*</span> <span class="mi">8</span><span class="p">))</span>
        <span class="n">mspass_object</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="n">DoubleVector</span><span class="p">(</span><span class="n">float_array</span><span class="p">)</span>
    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">mspass_object</span><span class="p">,</span> <span class="n">Seismogram</span><span class="p">):</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">mspass_object</span><span class="o">.</span><span class="n">is_defined</span><span class="p">(</span><span class="s2">&quot;npts&quot;</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">KeyError</span><span class="p">(</span><span class="s2">&quot;npts is not defined&quot;</span><span class="p">)</span>
        <span class="n">npts</span> <span class="o">=</span> <span class="n">mspass_object</span><span class="p">[</span><span class="s2">&quot;npts&quot;</span><span class="p">]</span>
        <span class="n">np_arr</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">frombuffer</span><span class="p">(</span><span class="n">fh</span><span class="o">.</span><span class="n">read</span><span class="p">(</span><span class="n">npts</span> <span class="o">*</span> <span class="mi">8</span> <span class="o">*</span> <span class="mi">3</span><span class="p">))</span>
        <span class="n">file_size</span> <span class="o">=</span> <span class="n">fh</span><span class="o">.</span><span class="n">tell</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">file_size</span> <span class="o">!=</span> <span class="n">npts</span> <span class="o">*</span> <span class="mi">8</span> <span class="o">*</span> <span class="mi">3</span><span class="p">:</span>
            <span class="c1"># Note we can only detect the cases where given npts is larger than</span>
            <span class="c1"># the number of points in the file</span>
            <span class="n">emess</span> <span class="o">=</span> <span class="p">(</span>
                <span class="s2">&quot;Size mismatch in sample data. Number of points in gridfs file = </span><span class="si">%d</span><span class="s2"> but expected </span><span class="si">%d</span><span class="s2">&quot;</span>
                <span class="o">%</span> <span class="p">(</span><span class="n">file_size</span> <span class="o">/</span> <span class="mi">8</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span> <span class="o">*</span> <span class="n">mspass_object</span><span class="p">[</span><span class="s2">&quot;npts&quot;</span><span class="p">]))</span>
            <span class="p">)</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="n">emess</span><span class="p">)</span>
        <span class="n">np_arr</span> <span class="o">=</span> <span class="n">np_arr</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">npts</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span><span class="o">.</span><span class="n">transpose</span><span class="p">()</span>
        <span class="n">mspass_object</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="n">dmatrix</span><span class="p">(</span><span class="n">np_arr</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">&quot;only TimeSeries and Seismogram are supported&quot;</span><span class="p">)</span>


<div class="viewcode-block" id="write_distributed_data"><a class="viewcode-back" href="../../../python_api/mspasspy.io.html#mspasspy.io.distributed.write_distributed_data">[docs]</a><span class="k">def</span> <span class="nf">write_distributed_data</span><span class="p">(</span>
    <span class="n">data</span><span class="p">,</span>
    <span class="n">db</span><span class="p">,</span>
    <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;promiscuous&quot;</span><span class="p">,</span>
    <span class="n">storage_mode</span><span class="o">=</span><span class="s2">&quot;gridfs&quot;</span><span class="p">,</span>
    <span class="nb">format</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">file_format</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">overwrite</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">exclude_keys</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">collection</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">data_tag</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">alg_name</span><span class="o">=</span><span class="s2">&quot;write_distributed_data&quot;</span><span class="p">,</span>
    <span class="n">alg_id</span><span class="o">=</span><span class="s2">&quot;0&quot;</span><span class="p">,</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    This function should be used to write an entire dataset that is to be handled</span>
<span class="sd">    by subsequent parallel operations.  The function can be thought of as</span>
<span class="sd">    writing the entire data set from a parallel container (rdd for spark</span>
<span class="sd">    implementations or bag for a dask implementatio) to storage. From the container,</span>
<span class="sd">    it will write to files distributedly using spark/dask, and then write to the</span>
<span class="sd">    database sequentially. The two parts are done in two functions: write_files,</span>
<span class="sd">    and write_to_db. It returns a dataframe of metadata for each object in the</span>
<span class="sd">    original container. The return value can be used as input for</span>
<span class="sd">    read_distributed_data() function.</span>

<span class="sd">    Objects should be written to different files, otherwise it may overwrite each other.</span>
<span class="sd">    dir and dfile should be stored in each object.</span>

<span class="sd">    :param data: the data to be written</span>
<span class="sd">    :type data: :class:`dask.bag.Bag` or :class:`pyspark.RDD`.</span>
<span class="sd">    :param db: the database from which the data are to be written.</span>
<span class="sd">    :type db: :class:`mspasspy.db.database.Database`.</span>
<span class="sd">    :param mspass_object: the object you want to save.</span>
<span class="sd">    :type mspass_object: either :class:`mspasspy.ccore.seismic.TimeSeries` or :class:`mspasspy.ccore.seismic.Seismogram`</span>
<span class="sd">    :param mode: This parameter defines how attributes defined with</span>
<span class="sd">        key-value pairs in MongoDB documents are to be handled on reading.</span>
<span class="sd">        By &quot;to be handled&quot; we mean how strongly to enforce name and type</span>
<span class="sd">        specification in the schema for the type of object being constructed.</span>
<span class="sd">        Options are [&#39;promiscuous&#39;,&#39;cautious&#39;,&#39;pedantic&#39;] with &#39;promiscuous&#39;</span>
<span class="sd">        being the default.  See the User&#39;s manual for more details on</span>
<span class="sd">        the concepts and how to use this option.</span>
<span class="sd">    :type mode: :class:`str`</span>
<span class="sd">    :param storage_mode: Must be either &quot;gridfs&quot; or &quot;file.  When set to</span>
<span class="sd">        &quot;gridfs&quot; the waveform data are stored internally and managed by</span>
<span class="sd">        MongoDB.  If set to &quot;file&quot; the data will be stored in a file system</span>
<span class="sd">        with the dir and dfile arguments defining a file name.   The</span>
<span class="sd">        default is &quot;gridfs&quot;.</span>
<span class="sd">    :type storage_mode: :class:`str`</span>
<span class="sd">    :param format: the format of the file. This can be one of the</span>
<span class="sd">        `supported formats &lt;https://docs.obspy.org/packages/autogen/obspy.core.stream.Stream.write.html#supported-formats&gt;`__</span>
<span class="sd">        of ObsPy writer. The default the python None which the method</span>
<span class="sd">        assumes means to store the data in its raw binary form.  The default</span>
<span class="sd">        should normally be used for efficiency.  Alternate formats are</span>
<span class="sd">        primarily a simple export mechanism.  See the User&#39;s manual for</span>
<span class="sd">        more details on data export.  Used only for &quot;file&quot; storage mode.</span>
<span class="sd">    :type format: :class:`str`</span>
<span class="sd">    :param overwrite:  If true gridfs data linked to the original</span>
<span class="sd">        waveform will be replaced by the sample data from this save.</span>
<span class="sd">        Default is false, and should be the normal use.  This option</span>
<span class="sd">        should never be used after a reduce operator as the parents</span>
<span class="sd">        are not tracked and the space advantage is likely minimal for</span>
<span class="sd">        the confusion it would cause.   This is most useful for light, stable</span>
<span class="sd">        preprocessing with a set of map operators to regularize a data</span>
<span class="sd">        set before more extensive processing.  It can only be used when</span>
<span class="sd">        storage_mode is set to gridfs.</span>
<span class="sd">    :type overwrite:  boolean</span>
<span class="sd">    :param exclude_keys: Metadata can often become contaminated with</span>
<span class="sd">        attributes that are no longer needed or a mismatch with the data.</span>
<span class="sd">        A type example is the bundle algorithm takes three TimeSeries</span>
<span class="sd">        objects and produces a single Seismogram from them.  That process</span>
<span class="sd">        can, and usually does, leave things like seed channel names and</span>
<span class="sd">        orientation attributes (hang and vang) from one of the components</span>
<span class="sd">        as extraneous baggage.   Use this of keys to prevent such attributes</span>
<span class="sd">        from being written to the output documents.  Not if the data being</span>
<span class="sd">        saved lack these keys nothing happens so it is safer, albeit slower,</span>
<span class="sd">        to have the list be as large as necessary to eliminate any potential</span>
<span class="sd">        debris.</span>
<span class="sd">    :type exclude_keys: a :class:`list` of :class:`str`</span>
<span class="sd">    :param collection: The default for this parameter is the python</span>
<span class="sd">        None.  The default should be used for all but data export functions.</span>
<span class="sd">        The normal behavior is for this writer to use the object</span>
<span class="sd">        data type to determine the schema is should use for any type or</span>
<span class="sd">        name enforcement.  This parameter allows an alernate collection to</span>
<span class="sd">        be used with or without some different name and type restrictions.</span>
<span class="sd">        The most common use of anything other than the default is an</span>
<span class="sd">        export to a diffrent format.</span>
<span class="sd">    :param data_tag: a user specified &quot;data_tag&quot; key.  See above and</span>
<span class="sd">        User&#39;s manual for guidance on how the use of this option.</span>
<span class="sd">    :type data_tag: :class:`str`</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># 1. write to file system, distributed, get the metadata</span>
    <span class="n">metadata_container</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">map</span><span class="p">(</span>
        <span class="k">lambda</span> <span class="n">cur</span><span class="p">:</span> <span class="n">write_files</span><span class="p">(</span>
            <span class="n">cur</span><span class="p">,</span> <span class="n">file_format</span><span class="p">,</span> <span class="n">storage_mode</span><span class="p">,</span> <span class="n">overwrite</span><span class="p">,</span> <span class="n">gfsh</span><span class="o">=</span><span class="n">gridfs</span><span class="o">.</span><span class="n">GridFS</span><span class="p">(</span><span class="n">db</span><span class="p">)</span>
        <span class="p">)</span>
    <span class="p">)</span>
    <span class="c1"># 2. write to database, sequential</span>
    <span class="c1"># convert the parallel container to list</span>
    <span class="k">if</span> <span class="nb">format</span> <span class="o">==</span> <span class="s2">&quot;spark&quot;</span><span class="p">:</span>
        <span class="n">md_list</span> <span class="o">=</span> <span class="n">metadata_container</span><span class="o">.</span><span class="n">collect</span><span class="p">()</span>  <span class="c1"># rdd -&gt; list</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">md_list</span> <span class="o">=</span> <span class="n">metadata_container</span><span class="o">.</span><span class="n">compute</span><span class="p">()</span>  <span class="c1"># bag -&gt; list</span>
    <span class="k">return</span> <span class="n">write_to_db</span><span class="p">(</span>
        <span class="n">db</span><span class="p">,</span>
        <span class="n">md_list</span><span class="p">,</span>
        <span class="n">mode</span><span class="o">=</span><span class="n">mode</span><span class="p">,</span>
        <span class="n">storage_mode</span><span class="o">=</span><span class="n">storage_mode</span><span class="p">,</span>
        <span class="nb">format</span><span class="o">=</span><span class="n">file_format</span><span class="p">,</span>
        <span class="n">overwrite</span><span class="o">=</span><span class="n">overwrite</span><span class="p">,</span>
        <span class="n">exclude_keys</span><span class="o">=</span><span class="n">exclude_keys</span><span class="p">,</span>
        <span class="n">collection</span><span class="o">=</span><span class="n">collection</span><span class="p">,</span>
        <span class="n">data_tag</span><span class="o">=</span><span class="n">data_tag</span><span class="p">,</span>
    <span class="p">)</span></div>


<div class="viewcode-block" id="write_to_db"><a class="viewcode-back" href="../../../python_api/mspasspy.io.html#mspasspy.io.distributed.write_to_db">[docs]</a><span class="k">def</span> <span class="nf">write_to_db</span><span class="p">(</span>
    <span class="n">db</span><span class="p">,</span>
    <span class="n">md_list</span><span class="p">,</span>
    <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;promiscuous&quot;</span><span class="p">,</span>
    <span class="n">storage_mode</span><span class="o">=</span><span class="s2">&quot;file&quot;</span><span class="p">,</span>
    <span class="nb">format</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">overwrite</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">exclude_keys</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">collection</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">data_tag</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">alg_name</span><span class="o">=</span><span class="s2">&quot;write_to_db&quot;</span><span class="p">,</span>
    <span class="n">alg_id</span><span class="o">=</span><span class="s2">&quot;0&quot;</span><span class="p">,</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Use this method to save a list of atomic data objects (TimeSeries or Seismogram)</span>
<span class="sd">    to be managed with MongoDB.  The Metadata are stored as documents in</span>
<span class="sd">    a MongoDB collection.  This method will not write data to file system,</span>
<span class="sd">    it only writes to the doc and to the database for every metadata of the</span>
<span class="sd">    target mspass object. Return type is a dataframe of metadata</span>
<span class="sd">    for the target mspass objects. The logic is same as Database.save_data().</span>
<span class="sd">    The function is the exact reverse of read_to_dataframe().</span>

<span class="sd">    Any errors messages held in the object being saved are always</span>
<span class="sd">    written to documents in MongoDB is a special collection defined in</span>
<span class="sd">    the schema.   Saving object level history is optional.</span>

<span class="sd">    There are multiple options described below.  One worth emphasizing is</span>
<span class="sd">    &quot;data_tag&quot;.   Such a tag is essential for intermediate saves of</span>
<span class="sd">    a dataset if there is no other unique way to distinguish the</span>
<span class="sd">    data in is current state from data saved earlier.  For example,</span>
<span class="sd">    consider a job that did nothing but read waveform segments spanning</span>
<span class="sd">    a long time period (e.g. day files),cutting out a shorter time window,</span>
<span class="sd">    and then saving windowed data.  Crafting an unambiguous query to</span>
<span class="sd">    find only the windowed data in that situation could be challenging</span>
<span class="sd">    or impossible.  Hence, we recommend a data tag always be used for</span>
<span class="sd">    most saves.</span>

<span class="sd">    The mode parameter needs to be understood by all users of this</span>
<span class="sd">    function.  All modes enforce a schema constraint for &quot;readonly&quot;</span>
<span class="sd">    attributes.   An immutable (readonly) attribute by definition</span>
<span class="sd">    should not be changed during processing.   During a save</span>
<span class="sd">    all attributes with a key defined as readonly are tested</span>
<span class="sd">    with a method in the Metadata container that keeps track of</span>
<span class="sd">    any Metadata changes.  If a readonly attribute is found to</span>
<span class="sd">    have been changed it will be renamed with the prefix</span>
<span class="sd">    &quot;READONLYERROR_&quot;, saved, and an error posted (e.g. if you try</span>
<span class="sd">    to alter site_lat (a readonly attribute) in a workflow when</span>
<span class="sd">    you save the waveform you will find an entry with the key</span>
<span class="sd">    READONERROR_site_lat.)   In the default &#39;promiscuous&#39; mode</span>
<span class="sd">    all other attributes are blindly saved to the database as</span>
<span class="sd">    name value pairs with no safeties.  In &#39;cautious&#39; mode we</span>
<span class="sd">    add a type check.  If the actual type of an attribute does not</span>
<span class="sd">    match what the schema expect, this method will try to fix the</span>
<span class="sd">    type error before saving the data.  If the conversion is</span>
<span class="sd">    successful it will be saved with a complaint error posted</span>
<span class="sd">    to elog.  If it fails, the attribute will not be saved, an</span>
<span class="sd">    additional error message will be posted, and the save</span>
<span class="sd">    algorithm continues.  In &#39;pedantic&#39; mode, in contrast, all</span>
<span class="sd">    type errors are considered to invalidate the data.</span>
<span class="sd">    Similar error messages to that in &#39;cautious&#39; mode are posted</span>
<span class="sd">    but any type errors will cause the datum passed as arg 0</span>
<span class="sd">    to be killed. The lesson is saves can leave entries that</span>
<span class="sd">    may need to be examined in elog and when really bad will</span>
<span class="sd">    cause the datum to be marked dead after the save.</span>

<span class="sd">    This method can throw an exception but only for errors in</span>
<span class="sd">    usage (i.e. arguments defined incorrectly)</span>

<span class="sd">    :param db: the database from which the data are to be written.</span>
<span class="sd">    :type db: :class:`mspasspy.db.database.Database`.</span>
<span class="sd">    :param md_list: the metadata list you want to save.</span>
<span class="sd">    :type md_list: :class:`list`</span>
<span class="sd">    :param mode: This parameter defines how attributes defined with</span>
<span class="sd">        key-value pairs in MongoDB documents are to be handled on reading.</span>
<span class="sd">        By &quot;to be handled&quot; we mean how strongly to enforce name and type</span>
<span class="sd">        specification in the schema for the type of object being constructed.</span>
<span class="sd">        Options are [&#39;promiscuous&#39;,&#39;cautious&#39;,&#39;pedantic&#39;] with &#39;promiscuous&#39;</span>
<span class="sd">        being the default.  See the User&#39;s manual for more details on</span>
<span class="sd">        the concepts and how to use this option.</span>
<span class="sd">    :type mode: :class:`str`</span>
<span class="sd">    :param storage_mode: Must be either &quot;gridfs&quot; or &quot;file.  When set to</span>
<span class="sd">        &quot;gridfs&quot; the waveform data are stored internally and managed by</span>
<span class="sd">        MongoDB.  If set to &quot;file&quot; the data will be stored in a file system</span>
<span class="sd">        with the dir and dfile arguments defining a file name.   The</span>
<span class="sd">        default is &quot;gridfs&quot;.</span>
<span class="sd">    :type storage_mode: :class:`str`</span>
<span class="sd">    :param format: the format of the file. This can be one of the</span>
<span class="sd">        `supported formats &lt;https://docs.obspy.org/packages/autogen/obspy.core.stream.Stream.write.html#supported-formats&gt;`__</span>
<span class="sd">        of ObsPy writer. The default the python None which the method</span>
<span class="sd">        assumes means to store the data in its raw binary form.  The default</span>
<span class="sd">        should normally be used for efficiency.  Alternate formats are</span>
<span class="sd">        primarily a simple export mechanism.  See the User&#39;s manual for</span>
<span class="sd">        more details on data export.  Used only for &quot;file&quot; storage mode.</span>
<span class="sd">    :type format: :class:`str`</span>
<span class="sd">    :param overwrite:  If true gridfs data linked to the original</span>
<span class="sd">        waveform will be replaced by the sample data from this save.</span>
<span class="sd">        Default is false, and should be the normal use.  This option</span>
<span class="sd">        should never be used after a reduce operator as the parents</span>
<span class="sd">        are not tracked and the space advantage is likely minimal for</span>
<span class="sd">        the confusion it would cause.   This is most useful for light, stable</span>
<span class="sd">        preprocessing with a set of map operators to regularize a data</span>
<span class="sd">        set before more extensive processing.  It can only be used when</span>
<span class="sd">        storage_mode is set to gridfs.</span>
<span class="sd">    :type overwrite:  boolean</span>
<span class="sd">    :param exclude_keys: Metadata can often become contaminated with</span>
<span class="sd">        attributes that are no longer needed or a mismatch with the data.</span>
<span class="sd">        A type example is the bundle algorithm takes three TimeSeries</span>
<span class="sd">        objects and produces a single Seismogram from them.  That process</span>
<span class="sd">        can, and usually does, leave things like seed channel names and</span>
<span class="sd">        orientation attributes (hang and vang) from one of the components</span>
<span class="sd">        as extraneous baggage.   Use this of keys to prevent such attributes</span>
<span class="sd">        from being written to the output documents.  Not if the data being</span>
<span class="sd">        saved lack these keys nothing happens so it is safer, albeit slower,</span>
<span class="sd">        to have the list be as large as necessary to eliminate any potential</span>
<span class="sd">        debris.</span>
<span class="sd">    :type exclude_keys: a :class:`list` of :class:`str`</span>
<span class="sd">    :param collection: The default for this parameter is the python</span>
<span class="sd">        None.  The default should be used for all but data export functions.</span>
<span class="sd">        The normal behavior is for this writer to use the object</span>
<span class="sd">        data type to determine the schema is should use for any type or</span>
<span class="sd">        name enforcement.  This parameter allows an alernate collection to</span>
<span class="sd">        be used with or without some different name and type restrictions.</span>
<span class="sd">        The most common use of anything other than the default is an</span>
<span class="sd">        export to a diffrent format.</span>
<span class="sd">    :param data_tag: a user specified &quot;data_tag&quot; key.  See above and</span>
<span class="sd">        User&#39;s manual for guidance on how the use of this option.</span>
<span class="sd">    :type data_tag: :class:`str`</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">mode</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;promiscuous&quot;</span><span class="p">,</span> <span class="s2">&quot;cautious&quot;</span><span class="p">,</span> <span class="s2">&quot;pedantic&quot;</span><span class="p">]:</span>
        <span class="k">raise</span> <span class="n">MsPASSError</span><span class="p">(</span>
            <span class="s2">&quot;only promiscuous, cautious and pedantic are supported, but </span><span class="si">{}</span><span class="s2"> is requested.&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                <span class="n">mode</span>
            <span class="p">),</span>
            <span class="s2">&quot;Fatal&quot;</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="k">for</span> <span class="n">md</span> <span class="ow">in</span> <span class="n">md_list</span><span class="p">:</span>
        <span class="c1"># below we try to capture permission issue before writing anything to the database.</span>
        <span class="c1"># However, in the case that a storage is almost full, exceptions can still be</span>
        <span class="c1"># thrown, which could mess up the database record.</span>
        <span class="k">if</span> <span class="n">storage_mode</span> <span class="o">==</span> <span class="s2">&quot;file&quot;</span><span class="p">:</span>
            <span class="k">if</span> <span class="p">(</span><span class="s2">&quot;dir&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">md</span><span class="p">)</span> <span class="ow">or</span> <span class="p">(</span><span class="s2">&quot;dfile&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">md</span><span class="p">):</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;dir or dfile is not specified in data object&quot;</span><span class="p">)</span>
            <span class="nb">dir</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">abspath</span><span class="p">(</span><span class="n">md</span><span class="p">[</span><span class="s2">&quot;dir&quot;</span><span class="p">])</span>
            <span class="n">dfile</span> <span class="o">=</span> <span class="n">md</span><span class="p">[</span><span class="s2">&quot;dfile&quot;</span><span class="p">]</span>
            <span class="k">if</span> <span class="nb">dir</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="nb">dir</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">getcwd</span><span class="p">()</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="nb">dir</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">abspath</span><span class="p">(</span><span class="nb">dir</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">dfile</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">dfile</span> <span class="o">=</span> <span class="n">db</span><span class="o">.</span><span class="n">_get_dfile_uuid</span><span class="p">(</span>
                    <span class="nb">format</span>
                <span class="p">)</span>  <span class="c1">#   If dfile name is not given, or defined in mspass_object, a new uuid will be generated</span>
            <span class="n">fname</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="nb">dir</span><span class="p">,</span> <span class="n">dfile</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">fname</span><span class="p">):</span>
                <span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">access</span><span class="p">(</span><span class="n">fname</span><span class="p">,</span> <span class="n">os</span><span class="o">.</span><span class="n">W_OK</span><span class="p">):</span>
                    <span class="k">raise</span> <span class="ne">PermissionError</span><span class="p">(</span>
                        <span class="s2">&quot;No write permission to the save file: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">fname</span><span class="p">)</span>
                    <span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="c1"># the following loop finds the top level of existing parents to fname</span>
                <span class="c1"># and check for write permission to that directory.</span>
                <span class="k">for</span> <span class="n">path_item</span> <span class="ow">in</span> <span class="n">pathlib</span><span class="o">.</span><span class="n">PurePath</span><span class="p">(</span><span class="n">fname</span><span class="p">)</span><span class="o">.</span><span class="n">parents</span><span class="p">:</span>
                    <span class="k">if</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">path_item</span><span class="p">):</span>
                        <span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">access</span><span class="p">(</span><span class="n">path_item</span><span class="p">,</span> <span class="n">os</span><span class="o">.</span><span class="n">W_OK</span> <span class="o">|</span> <span class="n">os</span><span class="o">.</span><span class="n">X_OK</span><span class="p">):</span>
                            <span class="k">raise</span> <span class="ne">PermissionError</span><span class="p">(</span>
                                <span class="s2">&quot;No write permission to the save directory: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                                    <span class="nb">dir</span>
                                <span class="p">)</span>
                            <span class="p">)</span>
                        <span class="k">break</span>

        <span class="n">schema</span> <span class="o">=</span> <span class="n">db</span><span class="o">.</span><span class="n">metadata_schema</span>
        <span class="k">if</span> <span class="n">md</span><span class="p">[</span><span class="s2">&quot;object_type&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;TimeSeries&quot;</span><span class="p">:</span>
            <span class="n">save_schema</span> <span class="o">=</span> <span class="n">schema</span><span class="o">.</span><span class="n">TimeSeries</span>
            <span class="n">atomic_type</span> <span class="o">=</span> <span class="n">AtomicType</span><span class="o">.</span><span class="n">TIMESERIES</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">save_schema</span> <span class="o">=</span> <span class="n">schema</span><span class="o">.</span><span class="n">Seismogram</span>
            <span class="n">atomic_type</span> <span class="o">=</span> <span class="n">AtomicType</span><span class="o">.</span><span class="n">SEISMOGRAM</span>

        <span class="c1"># should define wf_collection here because if the mspass_object is dead</span>
        <span class="k">if</span> <span class="n">collection</span><span class="p">:</span>
            <span class="n">wf_collection_name</span> <span class="o">=</span> <span class="n">collection</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># This returns a string that is the collection name for this atomic data type</span>
            <span class="c1"># A weird construct</span>
            <span class="n">wf_collection_name</span> <span class="o">=</span> <span class="n">save_schema</span><span class="o">.</span><span class="n">collection</span><span class="p">(</span><span class="s2">&quot;_id&quot;</span><span class="p">)</span>
        <span class="n">wf_collection</span> <span class="o">=</span> <span class="n">db</span><span class="p">[</span><span class="n">wf_collection_name</span><span class="p">]</span>

        <span class="k">if</span> <span class="n">md</span><span class="p">[</span><span class="s2">&quot;is_dead&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="kc">False</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">exclude_keys</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">exclude_keys</span> <span class="o">=</span> <span class="p">[]</span>

            <span class="c1"># This method of Metadata returns a list of all</span>
            <span class="c1"># attributes that were changed after creation of the</span>
            <span class="c1"># object to which they are attached.</span>
            <span class="n">changed_key_list</span> <span class="o">=</span> <span class="n">md</span><span class="o">.</span><span class="n">modified</span><span class="p">()</span>

            <span class="n">copied_metadata</span> <span class="o">=</span> <span class="n">md</span>

            <span class="c1"># clear all the aliases</span>
            <span class="c1"># TODO  check for potential bug in handling clear_aliases</span>
            <span class="c1"># and modified method - i.e. keys returned by modified may be</span>
            <span class="c1"># aliases</span>
            <span class="n">save_schema</span><span class="o">.</span><span class="n">clear_aliases</span><span class="p">(</span><span class="n">copied_metadata</span><span class="p">)</span>

            <span class="c1"># remove any values with only spaces</span>
            <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">copied_metadata</span><span class="p">:</span>
                <span class="k">if</span> <span class="ow">not</span> <span class="nb">str</span><span class="p">(</span><span class="n">copied_metadata</span><span class="p">[</span><span class="n">k</span><span class="p">])</span><span class="o">.</span><span class="n">strip</span><span class="p">():</span>
                    <span class="n">copied_metadata</span><span class="o">.</span><span class="n">erase</span><span class="p">(</span><span class="n">k</span><span class="p">)</span>

            <span class="c1"># remove any defined items in exclude list</span>
            <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">exclude_keys</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">copied_metadata</span><span class="p">:</span>
                    <span class="n">copied_metadata</span><span class="o">.</span><span class="n">erase</span><span class="p">(</span><span class="n">k</span><span class="p">)</span>
            <span class="c1"># the special mongodb key _id is currently set readonly in</span>
            <span class="c1"># the mspass schema.  It would be cleard in the following loop</span>
            <span class="c1"># but it is better to not depend on that external constraint.</span>
            <span class="c1"># The reason is the insert_one used below for wf collections</span>
            <span class="c1"># will silently update an existing record if the _id key</span>
            <span class="c1"># is present in the update record.  We want this method</span>
            <span class="c1"># to always save the current copy with a new id and so</span>
            <span class="c1"># we make sure we clear it</span>
            <span class="k">if</span> <span class="s2">&quot;_id&quot;</span> <span class="ow">in</span> <span class="n">copied_metadata</span><span class="p">:</span>
                <span class="n">copied_metadata</span><span class="o">.</span><span class="n">erase</span><span class="p">(</span><span class="s2">&quot;_id&quot;</span><span class="p">)</span>
            <span class="c1"># Now remove any readonly data</span>
            <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">copied_metadata</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
                <span class="k">if</span> <span class="n">save_schema</span><span class="o">.</span><span class="n">is_defined</span><span class="p">(</span><span class="n">k</span><span class="p">):</span>
                    <span class="k">if</span> <span class="n">save_schema</span><span class="o">.</span><span class="n">readonly</span><span class="p">(</span><span class="n">k</span><span class="p">):</span>
                        <span class="k">if</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">changed_key_list</span><span class="p">:</span>
                            <span class="n">newkey</span> <span class="o">=</span> <span class="s2">&quot;READONLYERROR_&quot;</span> <span class="o">+</span> <span class="n">k</span>
                            <span class="n">copied_metadata</span><span class="o">.</span><span class="n">change_key</span><span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="n">newkey</span><span class="p">)</span>
                            <span class="n">md</span><span class="p">[</span><span class="s2">&quot;history&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">elog</span><span class="o">.</span><span class="n">log_error</span><span class="p">(</span>
                                <span class="s2">&quot;Database.save_data&quot;</span><span class="p">,</span>
                                <span class="s2">&quot;readonly attribute with key=&quot;</span>
                                <span class="o">+</span> <span class="n">k</span>
                                <span class="o">+</span> <span class="s2">&quot; was improperly modified.  Saved changed value with key=&quot;</span>
                                <span class="o">+</span> <span class="n">newkey</span><span class="p">,</span>
                                <span class="n">ErrorSeverity</span><span class="o">.</span><span class="n">Complaint</span><span class="p">,</span>
                            <span class="p">)</span>
                        <span class="k">else</span><span class="p">:</span>
                            <span class="n">copied_metadata</span><span class="o">.</span><span class="n">erase</span><span class="p">(</span><span class="n">k</span><span class="p">)</span>
            <span class="c1"># Done editing, now we convert copied_metadata to a python dict</span>
            <span class="c1"># using this Metadata method or the long version when in cautious or pedantic mode</span>
            <span class="n">insertion_dict</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>
            <span class="k">if</span> <span class="n">mode</span> <span class="o">==</span> <span class="s2">&quot;promiscuous&quot;</span><span class="p">:</span>
                <span class="c1"># A python dictionary can use Metadata as a constructor due to</span>
                <span class="c1"># the way the bindings were defined</span>
                <span class="n">insertion_dict</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="n">copied_metadata</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="c1"># Other modes have to test every key and type of value</span>
                <span class="c1"># before continuing.  pedantic kills data with any problems</span>
                <span class="c1"># Cautious tries to fix the problem first</span>
                <span class="c1"># Note many errors can be posted - one for each problem key-value pair</span>
                <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">copied_metadata</span><span class="p">:</span>
                    <span class="k">if</span> <span class="n">save_schema</span><span class="o">.</span><span class="n">is_defined</span><span class="p">(</span><span class="n">k</span><span class="p">):</span>
                        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">copied_metadata</span><span class="p">[</span><span class="n">k</span><span class="p">],</span> <span class="n">save_schema</span><span class="o">.</span><span class="n">type</span><span class="p">(</span><span class="n">k</span><span class="p">)):</span>
                            <span class="n">insertion_dict</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">copied_metadata</span><span class="p">[</span><span class="n">k</span><span class="p">]</span>
                        <span class="k">else</span><span class="p">:</span>
                            <span class="k">if</span> <span class="n">mode</span> <span class="o">==</span> <span class="s2">&quot;pedantic&quot;</span><span class="p">:</span>
                                <span class="n">md</span><span class="p">[</span><span class="s2">&quot;is_dead&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">True</span>
                                <span class="n">message</span> <span class="o">=</span> <span class="s2">&quot;pedantic mode error:  key=&quot;</span> <span class="o">+</span> <span class="n">k</span>
                                <span class="n">value</span> <span class="o">=</span> <span class="n">copied_metadata</span><span class="p">[</span><span class="n">k</span><span class="p">]</span>
                                <span class="n">message</span> <span class="o">+=</span> <span class="p">(</span>
                                    <span class="s2">&quot; type of stored value=&quot;</span>
                                    <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">value</span><span class="p">))</span>
                                    <span class="o">+</span> <span class="s2">&quot; does not match schema expectation=&quot;</span>
                                    <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">save_schema</span><span class="o">.</span><span class="n">type</span><span class="p">(</span><span class="n">k</span><span class="p">))</span>
                                <span class="p">)</span>
                                <span class="n">md</span><span class="p">[</span><span class="s2">&quot;history&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">elog</span><span class="o">.</span><span class="n">log_error</span><span class="p">(</span>
                                    <span class="s2">&quot;Database.save_data&quot;</span><span class="p">,</span>
                                    <span class="s2">&quot;message&quot;</span><span class="p">,</span>
                                    <span class="n">ErrorSeverity</span><span class="o">.</span><span class="n">Invalid</span><span class="p">,</span>
                                <span class="p">)</span>
                            <span class="k">else</span><span class="p">:</span>
                                <span class="c1"># Careful if another mode is added here.  else means cautious in this logic</span>
                                <span class="k">try</span><span class="p">:</span>
                                    <span class="c1"># The following convert the actual value in a dict to a required type.</span>
                                    <span class="c1"># This is because the return of type() is the class reference.</span>
                                    <span class="n">insertion_dict</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">save_schema</span><span class="o">.</span><span class="n">type</span><span class="p">(</span><span class="n">k</span><span class="p">)(</span>
                                        <span class="n">copied_metadata</span><span class="p">[</span><span class="n">k</span><span class="p">]</span>
                                    <span class="p">)</span>
                                <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">err</span><span class="p">:</span>
                                    <span class="c1">#  cannot convert required keys -&gt; kill the object</span>
                                    <span class="k">if</span> <span class="n">save_schema</span><span class="o">.</span><span class="n">is_required</span><span class="p">(</span><span class="n">k</span><span class="p">):</span>
                                        <span class="n">md</span><span class="p">[</span><span class="s2">&quot;is_dead&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">True</span>
                                        <span class="n">message</span> <span class="o">=</span> <span class="s2">&quot;cautious mode error:  key=&quot;</span> <span class="o">+</span> <span class="n">k</span>
                                        <span class="n">message</span> <span class="o">+=</span> <span class="p">(</span>
                                            <span class="s2">&quot; Required key value could not be converted to required type=&quot;</span>
                                            <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">save_schema</span><span class="o">.</span><span class="n">type</span><span class="p">(</span><span class="n">k</span><span class="p">))</span>
                                            <span class="o">+</span> <span class="s2">&quot; actual type=&quot;</span>
                                            <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">copied_metadata</span><span class="p">[</span><span class="n">k</span><span class="p">]))</span>
                                        <span class="p">)</span>
                                        <span class="n">message</span> <span class="o">+=</span> <span class="p">(</span>
                                            <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Python error exception message caught:</span><span class="se">\n</span><span class="s2">&quot;</span>
                                        <span class="p">)</span>
                                        <span class="n">message</span> <span class="o">+=</span> <span class="nb">str</span><span class="p">(</span><span class="n">err</span><span class="p">)</span>
                                        <span class="n">md</span><span class="p">[</span><span class="s2">&quot;history&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">elog</span><span class="o">.</span><span class="n">log_error</span><span class="p">(</span>
                                            <span class="s2">&quot;Database.save&quot;</span><span class="p">,</span>
                                            <span class="n">message</span><span class="p">,</span>
                                            <span class="n">ErrorSeverity</span><span class="o">.</span><span class="n">Invalid</span><span class="p">,</span>
                                        <span class="p">)</span>
                                    <span class="c1"># cannot convert normal keys -&gt; erase the key</span>
                                    <span class="c1"># TODO should we post a Complaint entry to the elog?</span>
                                    <span class="k">else</span><span class="p">:</span>
                                        <span class="n">copied_metadata</span><span class="o">.</span><span class="n">erase</span><span class="p">(</span><span class="n">k</span><span class="p">)</span>

        <span class="c1"># Note we jump here immediately if mspass_object was marked dead</span>
        <span class="c1"># on entry.  Data can, however, be killed in metadata section</span>
        <span class="c1"># above so we need repeat the test for live</span>
        <span class="k">if</span> <span class="n">md</span><span class="p">[</span><span class="s2">&quot;is_dead&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="kc">False</span><span class="p">:</span>
            <span class="n">insertion_dict</span><span class="p">[</span><span class="s2">&quot;storage_mode&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">storage_mode</span>
            <span class="n">gridfs_id</span> <span class="o">=</span> <span class="kc">None</span>

            <span class="k">if</span> <span class="n">storage_mode</span> <span class="o">==</span> <span class="s2">&quot;file&quot;</span><span class="p">:</span>
                <span class="c1"># TODO:  be sure this can&#39;t throw an exception</span>
<span class="w">                </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">                foff, nbytes = self._save_data_to_dfile(</span>
<span class="sd">                    mspass_object, dir, dfile, format=format</span>
<span class="sd">                )</span>
<span class="sd">                &quot;&quot;&quot;</span>
                <span class="n">insertion_dict</span><span class="p">[</span><span class="s2">&quot;dir&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="nb">dir</span>
                <span class="n">insertion_dict</span><span class="p">[</span><span class="s2">&quot;dfile&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">dfile</span>
                <span class="n">insertion_dict</span><span class="p">[</span><span class="s2">&quot;foff&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">md</span><span class="p">[</span><span class="s2">&quot;foff&quot;</span><span class="p">]</span>
                <span class="k">if</span> <span class="nb">format</span><span class="p">:</span>
                    <span class="n">insertion_dict</span><span class="p">[</span><span class="s2">&quot;nbytes&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">md</span><span class="p">[</span><span class="s2">&quot;nbytes&quot;</span><span class="p">]</span>
                    <span class="n">insertion_dict</span><span class="p">[</span><span class="s2">&quot;format&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="nb">format</span>
            <span class="k">elif</span> <span class="n">storage_mode</span> <span class="o">==</span> <span class="s2">&quot;gridfs&quot;</span><span class="p">:</span>
                <span class="n">insertion_dict</span><span class="p">[</span><span class="s2">&quot;gridfs_id&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">md</span><span class="p">[</span><span class="s2">&quot;gridfs_id&quot;</span><span class="p">]</span>
                <span class="c1"># TODO will support url mode later</span>
                <span class="c1"># elif storage_mode == &quot;url&quot;:</span>
                <span class="c1">#    pass</span>

            <span class="c1"># save history if not empty</span>
            <span class="n">history_obj_id_name</span> <span class="o">=</span> <span class="p">(</span>
                <span class="n">db</span><span class="o">.</span><span class="n">database_schema</span><span class="o">.</span><span class="n">default_name</span><span class="p">(</span><span class="s2">&quot;history_object&quot;</span><span class="p">)</span> <span class="o">+</span> <span class="s2">&quot;_id&quot;</span>
            <span class="p">)</span>
            <span class="n">history_object_id</span> <span class="o">=</span> <span class="kc">None</span>
            <span class="k">if</span> <span class="n">md</span><span class="p">[</span><span class="s2">&quot;history&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">is_empty</span><span class="p">():</span>
                <span class="c1"># Use this trick in update_metadata too. None is needed to</span>
                <span class="c1"># avoid a TypeError exception if the name is not defined.</span>
                <span class="c1"># could do this with a conditional as an alternative</span>
                <span class="n">insertion_dict</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="n">history_obj_id_name</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="c1"># optional history save - only done if history container is not empty</span>
                <span class="n">history_object_id</span> <span class="o">=</span> <span class="n">_save_history</span><span class="p">(</span>
                    <span class="n">db</span><span class="p">,</span> <span class="n">md</span><span class="p">,</span> <span class="n">save_schema</span><span class="p">,</span> <span class="n">atomic_type</span><span class="p">,</span> <span class="n">alg_name</span><span class="p">,</span> <span class="n">alg_id</span>
                <span class="p">)</span>
                <span class="n">insertion_dict</span><span class="p">[</span><span class="n">history_obj_id_name</span><span class="p">]</span> <span class="o">=</span> <span class="n">history_object_id</span>

            <span class="c1"># add tag</span>
            <span class="k">if</span> <span class="n">data_tag</span><span class="p">:</span>
                <span class="n">insertion_dict</span><span class="p">[</span><span class="s2">&quot;data_tag&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">data_tag</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="c1"># We need to clear data tag if was previously defined in</span>
                <span class="c1"># this case or a the old tag will be saved with this datum</span>
                <span class="k">if</span> <span class="s2">&quot;data_tag&quot;</span> <span class="ow">in</span> <span class="n">insertion_dict</span><span class="p">:</span>
                    <span class="n">insertion_dict</span><span class="o">.</span><span class="n">erase</span><span class="p">(</span><span class="s2">&quot;data_tag&quot;</span><span class="p">)</span>
            <span class="c1"># We don&#39;t want an elog_id in the insertion at this point.</span>
            <span class="c1"># A option to consider is if we need an update after _save_elog</span>
            <span class="c1"># section below to post elog_id back.</span>

            <span class="c1"># test will fail here because there might be some Complaint elog post to the wf above</span>
            <span class="c1"># we need to save the elog and get the elog_id</span>
            <span class="c1"># then associate with the wf document so that we could insert in the wf_collection</span>

            <span class="c1"># save elogs if the size of elog is greater than 0</span>
            <span class="n">elog_id</span> <span class="o">=</span> <span class="kc">None</span>
            <span class="k">if</span> <span class="n">md</span><span class="p">[</span><span class="s2">&quot;history&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">elog</span><span class="o">.</span><span class="n">size</span><span class="p">()</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">elog_id_name</span> <span class="o">=</span> <span class="n">db</span><span class="o">.</span><span class="n">database_schema</span><span class="o">.</span><span class="n">default_name</span><span class="p">(</span><span class="s2">&quot;elog&quot;</span><span class="p">)</span> <span class="o">+</span> <span class="s2">&quot;_id&quot;</span>
                <span class="c1"># elog ids will be updated in the wf col when saving metadata</span>
                <span class="n">elog_id</span> <span class="o">=</span> <span class="n">_save_elog</span><span class="p">(</span><span class="n">db</span><span class="p">,</span> <span class="n">md</span><span class="p">,</span> <span class="n">save_schema</span><span class="p">,</span> <span class="n">elog_id</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
                <span class="n">insertion_dict</span><span class="p">[</span><span class="n">elog_id_name</span><span class="p">]</span> <span class="o">=</span> <span class="n">elog_id</span>

            <span class="c1"># history attribute is redundant</span>
            <span class="n">insertion_dict</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;history&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
            <span class="c1"># finally ready to insert the wf doc - keep the id as we&#39;ll need</span>
            <span class="c1"># it for tagging any elog entries</span>
            <span class="n">wfid</span> <span class="o">=</span> <span class="n">wf_collection</span><span class="o">.</span><span class="n">insert_one</span><span class="p">(</span><span class="n">insertion_dict</span><span class="p">)</span><span class="o">.</span><span class="n">inserted_id</span>
            <span class="c1"># Put wfid into the object&#39;s meta as the new definition of</span>
            <span class="c1"># the parent of this waveform</span>
            <span class="n">md</span><span class="p">[</span><span class="s2">&quot;_id&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">wfid</span>

            <span class="c1"># we may probably set the gridfs_id field in the mspass_object</span>
            <span class="k">if</span> <span class="n">gridfs_id</span><span class="p">:</span>
                <span class="n">md</span><span class="p">[</span><span class="s2">&quot;gridfs_id&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">gridfs_id</span>
            <span class="c1"># we may probably set the history_object_id field in the mspass_object</span>
            <span class="k">if</span> <span class="n">history_object_id</span><span class="p">:</span>
                <span class="n">md</span><span class="p">[</span><span class="n">history_obj_id_name</span><span class="p">]</span> <span class="o">=</span> <span class="n">history_object_id</span>
            <span class="c1"># we may probably set the elog_id field in the mspass_object</span>
            <span class="k">if</span> <span class="n">elog_id</span><span class="p">:</span>
                <span class="n">md</span><span class="p">[</span><span class="n">elog_id_name</span><span class="p">]</span> <span class="o">=</span> <span class="n">elog_id</span>

            <span class="c1"># Empty error logs are skipped.  When nonzero tag them with tid</span>
            <span class="c1"># just returned</span>
            <span class="k">if</span> <span class="n">md</span><span class="p">[</span><span class="s2">&quot;history&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">elog</span><span class="o">.</span><span class="n">size</span><span class="p">()</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="c1"># elog_id_name = self.database_schema.default_name(&#39;elog&#39;) + &#39;_id&#39;</span>
                <span class="c1"># _save_elog uses a  null id as a signal to add a new record</span>
                <span class="c1"># When we land here the record must be new since it is</span>
                <span class="c1"># associated with a new wf document.  elog_id=None is default</span>
                <span class="c1"># but set it explicitly for clarity</span>

                <span class="c1"># This is comment out becuase we need to save it before inserting into the wf_collection</span>
                <span class="c1"># elog_id = self._save_elog(mspass_object, elog_id=None)</span>

                <span class="c1"># cross reference for elog entry, assoicate the wfid to the elog entry</span>
                <span class="n">elog_col</span> <span class="o">=</span> <span class="n">db</span><span class="p">[</span><span class="n">db</span><span class="o">.</span><span class="n">database_schema</span><span class="o">.</span><span class="n">default_name</span><span class="p">(</span><span class="s2">&quot;elog&quot;</span><span class="p">)]</span>
                <span class="n">wf_id_name</span> <span class="o">=</span> <span class="n">wf_collection_name</span> <span class="o">+</span> <span class="s2">&quot;_id&quot;</span>
                <span class="n">filter_</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;_id&quot;</span><span class="p">:</span> <span class="n">insertion_dict</span><span class="p">[</span><span class="n">elog_id_name</span><span class="p">]}</span>
                <span class="n">elog_col</span><span class="o">.</span><span class="n">update_one</span><span class="p">(</span><span class="n">filter_</span><span class="p">,</span> <span class="p">{</span><span class="s2">&quot;$set&quot;</span><span class="p">:</span> <span class="p">{</span><span class="n">wf_id_name</span><span class="p">:</span> <span class="n">md</span><span class="p">[</span><span class="s2">&quot;_id&quot;</span><span class="p">]}})</span>
            <span class="c1"># When history is enable we need to do an update to put the</span>
            <span class="c1"># wf collection id as a cross-reference.    Any value stored</span>
            <span class="c1"># above with saave_history may be incorrect.  We use a</span>
            <span class="c1"># stock test with the is_empty method for know if history data is present</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">md</span><span class="p">[</span><span class="s2">&quot;history&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">is_empty</span><span class="p">():</span>
                <span class="n">history_object_col</span> <span class="o">=</span> <span class="n">db</span><span class="p">[</span>
                    <span class="n">db</span><span class="o">.</span><span class="n">database_schema</span><span class="o">.</span><span class="n">default_name</span><span class="p">(</span><span class="s2">&quot;history_object&quot;</span><span class="p">)</span>
                <span class="p">]</span>
                <span class="n">wf_id_name</span> <span class="o">=</span> <span class="n">wf_collection_name</span> <span class="o">+</span> <span class="s2">&quot;_id&quot;</span>
                <span class="n">filter_</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;_id&quot;</span><span class="p">:</span> <span class="n">history_object_id</span><span class="p">}</span>
                <span class="n">update_dict</span> <span class="o">=</span> <span class="p">{</span><span class="n">wf_id_name</span><span class="p">:</span> <span class="n">wfid</span><span class="p">}</span>
                <span class="n">history_object_col</span><span class="o">.</span><span class="n">update_one</span><span class="p">(</span><span class="n">filter_</span><span class="p">,</span> <span class="p">{</span><span class="s2">&quot;$set&quot;</span><span class="p">:</span> <span class="n">update_dict</span><span class="p">})</span>

        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># We land here when the input is dead or was killed during a</span>
            <span class="c1"># cautious or pedantic mode edit of the metadata.</span>
            <span class="n">elog_id_name</span> <span class="o">=</span> <span class="n">db</span><span class="o">.</span><span class="n">database_schema</span><span class="o">.</span><span class="n">default_name</span><span class="p">(</span><span class="s2">&quot;elog&quot;</span><span class="p">)</span> <span class="o">+</span> <span class="s2">&quot;_id&quot;</span>
            <span class="k">if</span> <span class="n">elog_id_name</span> <span class="ow">in</span> <span class="n">md</span><span class="p">:</span>
                <span class="n">old_elog_id</span> <span class="o">=</span> <span class="n">md</span><span class="p">[</span><span class="n">elog_id_name</span><span class="p">]</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">old_elog_id</span> <span class="o">=</span> <span class="kc">None</span>
            <span class="n">elog_id</span> <span class="o">=</span> <span class="n">_save_elog</span><span class="p">(</span><span class="n">db</span><span class="p">,</span> <span class="n">md</span><span class="p">,</span> <span class="n">save_schema</span><span class="p">,</span> <span class="n">elog_id</span><span class="o">=</span><span class="n">old_elog_id</span><span class="p">)</span>
        <span class="c1"># Both live and dead data land here.</span>

    <span class="c1"># convert list of metadata to dataframe</span>
    <span class="k">return</span> <span class="n">pd</span><span class="o">.</span><span class="n">json_normalize</span><span class="p">(</span><span class="nb">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">cur</span><span class="p">:</span> <span class="n">cur</span><span class="o">.</span><span class="n">todict</span><span class="p">(),</span> <span class="n">md_list</span><span class="p">))</span></div>


<div class="viewcode-block" id="write_files"><a class="viewcode-back" href="../../../python_api/mspasspy.io.html#mspasspy.io.distributed.write_files">[docs]</a><span class="k">def</span> <span class="nf">write_files</span><span class="p">(</span>
    <span class="n">mspass_object</span><span class="p">,</span>
    <span class="nb">format</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">storage_mode</span><span class="o">=</span><span class="s2">&quot;file&quot;</span><span class="p">,</span>
    <span class="n">overwrite</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">gfsh</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    This is the writer for writing the object to storage. Return type is the</span>
<span class="sd">    metadata of the original object with some more parameters added, including</span>
<span class="sd">    storage_mode, history, whether the object is alive. This function is</span>
<span class="sd">    the reverse of read_files().</span>

<span class="sd">    :param mspass_object: the object you want to read.</span>
<span class="sd">    :type mspass_object: either :class:`mspasspy.ccore.seismic.TimeSeries` or :class:`mspasspy.ccore.seismic.Seismogram`</span>
<span class="sd">    :param object_doc: document of the object in the database</span>
<span class="sd">    :type object_doc: class:`dict`.</span>
<span class="sd">    :type format: :class:`str`</span>
<span class="sd">    :param storage_mode: Must be either &quot;gridfs&quot; or &quot;file.  When set to</span>
<span class="sd">        &quot;gridfs&quot; the waveform data are stored internally and managed by</span>
<span class="sd">        MongoDB.  If set to &quot;file&quot; the data will be stored in a file system</span>
<span class="sd">        with the dir and dfile arguments defining a file name.   The</span>
<span class="sd">        default is &quot;gridfs&quot;.</span>
<span class="sd">    :type storage_mode: :class:`str`</span>
<span class="sd">    :param overwrite:  If true gridfs data linked to the original</span>
<span class="sd">        waveform will be replaced by the sample data from this save.</span>
<span class="sd">        Default is false, and should be the normal use.  This option</span>
<span class="sd">        should never be used after a reduce operator as the parents</span>
<span class="sd">        are not tracked and the space advantage is likely minimal for</span>
<span class="sd">        the confusion it would cause.   This is most useful for light, stable</span>
<span class="sd">        preprocessing with a set of map operators to regularize a data</span>
<span class="sd">        set before more extensive processing.  It can only be used when</span>
<span class="sd">        storage_mode is set to gridfs.</span>
<span class="sd">    :type overwrite:  boolean</span>
<span class="sd">    :param gfsh: GridFS object</span>
<span class="sd">    :type gfsh: :class:`gridfs.GridFS`</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">mspass_object</span><span class="p">,</span> <span class="p">(</span><span class="n">TimeSeries</span><span class="p">,</span> <span class="n">Seismogram</span><span class="p">)):</span>
        <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">&quot;only TimeSeries and Seismogram are supported&quot;</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">storage_mode</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;file&quot;</span><span class="p">,</span> <span class="s2">&quot;gridfs&quot;</span><span class="p">]:</span>
        <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">&quot;Unknown storage mode: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">storage_mode</span><span class="p">))</span>

    <span class="n">mspass_object</span><span class="p">[</span><span class="s2">&quot;storage_mode&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">storage_mode</span>

    <span class="k">if</span> <span class="n">mspass_object</span><span class="o">.</span><span class="n">live</span><span class="p">:</span>
        <span class="n">mspass_object</span><span class="p">[</span><span class="s2">&quot;is_dead&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">False</span>

        <span class="c1"># FIXME starttime will be automatically created in this function</span>
        <span class="n">Database</span><span class="o">.</span><span class="n">_sync_metadata_before_update</span><span class="p">(</span><span class="n">mspass_object</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">storage_mode</span> <span class="o">==</span> <span class="s2">&quot;file&quot;</span><span class="p">:</span>
            <span class="n">foff</span><span class="p">,</span> <span class="n">nbytes</span> <span class="o">=</span> <span class="n">Database</span><span class="o">.</span><span class="n">_save_data_to_dfile</span><span class="p">(</span>
                <span class="n">mspass_object</span><span class="p">,</span>
                <span class="n">mspass_object</span><span class="p">[</span><span class="s2">&quot;dir&quot;</span><span class="p">],</span>
                <span class="n">mspass_object</span><span class="p">[</span><span class="s2">&quot;dfile&quot;</span><span class="p">],</span>
                <span class="nb">format</span><span class="o">=</span><span class="nb">format</span><span class="p">,</span>
            <span class="p">)</span>

            <span class="n">mspass_object</span><span class="p">[</span><span class="s2">&quot;foff&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">foff</span>
            <span class="n">mspass_object</span><span class="p">[</span><span class="s2">&quot;nbytes&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">nbytes</span>
        <span class="k">elif</span> <span class="n">storage_mode</span> <span class="o">==</span> <span class="s2">&quot;gridfs&quot;</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">overwrite</span> <span class="ow">and</span> <span class="s2">&quot;gridfs_id&quot;</span> <span class="ow">in</span> <span class="n">mspass_object</span><span class="p">:</span>
                <span class="n">gridfs_id</span> <span class="o">=</span> <span class="n">_save_data_to_gridfs</span><span class="p">(</span>
                    <span class="n">gfsh</span><span class="p">,</span> <span class="n">mspass_object</span><span class="p">,</span> <span class="n">mspass_object</span><span class="p">[</span><span class="s2">&quot;gridfs_id&quot;</span><span class="p">]</span>
                <span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">gridfs_id</span> <span class="o">=</span> <span class="n">_save_data_to_gridfs</span><span class="p">(</span><span class="n">gfsh</span><span class="p">,</span> <span class="n">mspass_object</span><span class="p">)</span>
            <span class="n">mspass_object</span><span class="p">[</span><span class="s2">&quot;gridfs_id&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">gridfs_id</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">mspass_object</span><span class="p">[</span><span class="s2">&quot;is_dead&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">True</span>

    <span class="n">md</span> <span class="o">=</span> <span class="n">Metadata</span><span class="p">(</span><span class="n">mspass_object</span><span class="p">)</span>
    <span class="n">md</span><span class="p">[</span><span class="s2">&quot;history&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">ProcessingHistory</span><span class="p">(</span><span class="n">mspass_object</span><span class="p">)</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">mspass_object</span><span class="p">,</span> <span class="n">TimeSeries</span><span class="p">):</span>
        <span class="n">md</span><span class="p">[</span><span class="s2">&quot;object_type&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;TimeSeries&quot;</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">md</span><span class="p">[</span><span class="s2">&quot;object_type&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;Seismogram&quot;</span>
    <span class="k">return</span> <span class="n">md</span></div>


<span class="k">def</span> <span class="nf">_save_data_to_gridfs</span><span class="p">(</span><span class="n">gfsh</span><span class="p">,</span> <span class="n">mspass_object</span><span class="p">,</span> <span class="n">gridfs_id</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Save a mspasspy object sample data to MongoDB grid file system. We recommend to use this method</span>
<span class="sd">    for saving a mspasspy object inside MongoDB. This is similar to database._save_data_to_gridfs(),</span>
<span class="sd">    but here we have gfsh as a parameter to avoid using database object.</span>

<span class="sd">    :param gfsh: GridFS object</span>
<span class="sd">    :type gfsh: :class:`gridfs.GridFS`</span>
<span class="sd">    :param mspass_object: the target object.</span>
<span class="sd">    :type mspass_object: either :class:`mspasspy.ccore.seismic.TimeSeries` or :class:`mspasspy.ccore.seismic.Seismogram`</span>
<span class="sd">    :param gridfs_id: if the data is already stored and you want to update it, you should provide the object id</span>
<span class="sd">    of the previous data, which will be deleted. A new document will be inserted instead.</span>
<span class="sd">    :type gridfs_id: :class:`bson.objectid.ObjectId`.</span>
<span class="sd">    :return inserted gridfs object id.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">gridfs_id</span> <span class="ow">and</span> <span class="n">gfsh</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">gridfs_id</span><span class="p">):</span>
        <span class="n">gfsh</span><span class="o">.</span><span class="n">delete</span><span class="p">(</span><span class="n">gridfs_id</span><span class="p">)</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">mspass_object</span><span class="p">,</span> <span class="n">Seismogram</span><span class="p">):</span>
        <span class="n">ub</span> <span class="o">=</span> <span class="nb">bytes</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">mspass_object</span><span class="o">.</span><span class="n">data</span><span class="p">)</span><span class="o">.</span><span class="n">transpose</span><span class="p">())</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">ub</span> <span class="o">=</span> <span class="nb">bytes</span><span class="p">(</span><span class="n">mspass_object</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">gfsh</span><span class="o">.</span><span class="n">put</span><span class="p">(</span><span class="n">ub</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">_save_elog</span><span class="p">(</span><span class="n">db</span><span class="p">,</span> <span class="n">md</span><span class="p">,</span> <span class="n">update_metadata_def</span><span class="p">,</span> <span class="n">elog_id</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">collection</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Save error log for a metadata object, which contains an error log object with key &quot;history&quot; used to post any</span>
<span class="sd">    errors handled by processing functions. This function will delete the old elog entry if `elog_id` is given.</span>

<span class="sd">    :param db: the database from which the data are to be written.</span>
<span class="sd">    :type db: :class:`mspasspy.db.database.Database`.</span>
<span class="sd">    :param md: the metadata of the target object.</span>
<span class="sd">    :type md: :class:`mspasspy.ccore.utility.Metadata`.</span>
<span class="sd">    :param update_metadata_def: the metadata schema to save.</span>
<span class="sd">    :type update_metadata_def: :class:`mspasspy.db.schema.MDSchemaDefinition`.</span>
<span class="sd">    :param elog_id: the previous elog object id to be appended with.</span>
<span class="sd">    :type elog_id: :class:`bson.objectid.ObjectId`</span>
<span class="sd">    :param collection: the collection that you want to save the elogs. If not specified, use the defined</span>
<span class="sd">    collection in the schema.</span>
<span class="sd">    :return: updated elog_id.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">wf_id_name</span> <span class="o">=</span> <span class="n">update_metadata_def</span><span class="o">.</span><span class="n">collection</span><span class="p">(</span><span class="s2">&quot;_id&quot;</span><span class="p">)</span> <span class="o">+</span> <span class="s2">&quot;_id&quot;</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="n">collection</span><span class="p">:</span>
        <span class="n">collection</span> <span class="o">=</span> <span class="n">db</span><span class="o">.</span><span class="n">database_schema</span><span class="o">.</span><span class="n">default_name</span><span class="p">(</span><span class="s2">&quot;elog&quot;</span><span class="p">)</span>

    <span class="c1"># TODO: Need to discuss whether the _id should be linked in a dead elog entry. It</span>
    <span class="c1"># might be confusing to link the dead elog to an alive wf record.</span>
    <span class="n">oid</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="k">if</span> <span class="s2">&quot;_id&quot;</span> <span class="ow">in</span> <span class="n">md</span><span class="p">:</span>
        <span class="n">oid</span> <span class="o">=</span> <span class="n">md</span><span class="p">[</span><span class="s2">&quot;_id&quot;</span><span class="p">]</span>

    <span class="n">elog</span> <span class="o">=</span> <span class="n">md</span><span class="p">[</span><span class="s2">&quot;history&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">elog</span>
    <span class="n">n</span> <span class="o">=</span> <span class="n">elog</span><span class="o">.</span><span class="n">size</span><span class="p">()</span>
    <span class="k">if</span> <span class="n">n</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">logdata</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">docentry</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;logdata&quot;</span><span class="p">:</span> <span class="n">logdata</span><span class="p">}</span>
        <span class="n">errs</span> <span class="o">=</span> <span class="n">elog</span><span class="o">.</span><span class="n">get_error_log</span><span class="p">()</span>
        <span class="n">jobid</span> <span class="o">=</span> <span class="n">elog</span><span class="o">.</span><span class="n">get_job_id</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">errs</span><span class="p">:</span>
            <span class="n">logdata</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                <span class="p">{</span>
                    <span class="s2">&quot;job_id&quot;</span><span class="p">:</span> <span class="n">jobid</span><span class="p">,</span>
                    <span class="s2">&quot;algorithm&quot;</span><span class="p">:</span> <span class="n">x</span><span class="o">.</span><span class="n">algorithm</span><span class="p">,</span>
                    <span class="s2">&quot;badness&quot;</span><span class="p">:</span> <span class="nb">str</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">badness</span><span class="p">),</span>
                    <span class="s2">&quot;error_message&quot;</span><span class="p">:</span> <span class="n">x</span><span class="o">.</span><span class="n">message</span><span class="p">,</span>
                    <span class="s2">&quot;process_id&quot;</span><span class="p">:</span> <span class="n">x</span><span class="o">.</span><span class="n">p_id</span><span class="p">,</span>
                <span class="p">}</span>
            <span class="p">)</span>
        <span class="k">if</span> <span class="n">oid</span><span class="p">:</span>
            <span class="n">docentry</span><span class="p">[</span><span class="n">wf_id_name</span><span class="p">]</span> <span class="o">=</span> <span class="n">oid</span>

        <span class="k">if</span> <span class="n">md</span><span class="p">[</span><span class="s2">&quot;is_dead&quot;</span><span class="p">]:</span>
            <span class="c1"># history attribute is redundant</span>
            <span class="n">md</span><span class="o">.</span><span class="n">erase</span><span class="p">(</span><span class="s2">&quot;history&quot;</span><span class="p">)</span>
            <span class="n">docentry</span><span class="p">[</span><span class="s2">&quot;tombstone&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="n">md</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">elog_id</span><span class="p">:</span>
            <span class="c1"># append elog</span>
            <span class="n">elog_doc</span> <span class="o">=</span> <span class="n">db</span><span class="p">[</span><span class="n">collection</span><span class="p">]</span><span class="o">.</span><span class="n">find_one</span><span class="p">({</span><span class="s2">&quot;_id&quot;</span><span class="p">:</span> <span class="n">elog_id</span><span class="p">})</span>
            <span class="c1"># only append when previous elog exists</span>
            <span class="k">if</span> <span class="n">elog_doc</span><span class="p">:</span>
                <span class="c1"># if the same object was updated twice, the elog entry will be duplicated</span>
                <span class="c1"># the following list comprehension line removes the duplicates and preserves</span>
                <span class="c1"># the order. May need some practice to see if such a behavior makes sense.</span>
                <span class="p">[</span>
                    <span class="n">elog_doc</span><span class="p">[</span><span class="s2">&quot;logdata&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
                    <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">logdata</span>
                    <span class="k">if</span> <span class="n">x</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">elog_doc</span><span class="p">[</span><span class="s2">&quot;logdata&quot;</span><span class="p">]</span>
                <span class="p">]</span>
                <span class="n">docentry</span><span class="p">[</span><span class="s2">&quot;logdata&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">elog_doc</span><span class="p">[</span><span class="s2">&quot;logdata&quot;</span><span class="p">]</span>
                <span class="n">db</span><span class="p">[</span><span class="n">collection</span><span class="p">]</span><span class="o">.</span><span class="n">delete_one</span><span class="p">({</span><span class="s2">&quot;_id&quot;</span><span class="p">:</span> <span class="n">elog_id</span><span class="p">})</span>
            <span class="c1"># note that is should be impossible for the old elog to have tombstone entry</span>
            <span class="c1"># so we ignore the handling of that attribute here.</span>
            <span class="n">ret_elog_id</span> <span class="o">=</span> <span class="n">db</span><span class="p">[</span><span class="n">collection</span><span class="p">]</span><span class="o">.</span><span class="n">insert_one</span><span class="p">(</span><span class="n">docentry</span><span class="p">)</span><span class="o">.</span><span class="n">inserted_id</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># new insertion</span>
            <span class="n">ret_elog_id</span> <span class="o">=</span> <span class="n">db</span><span class="p">[</span><span class="n">collection</span><span class="p">]</span><span class="o">.</span><span class="n">insert_one</span><span class="p">(</span><span class="n">docentry</span><span class="p">)</span><span class="o">.</span><span class="n">inserted_id</span>
        <span class="k">return</span> <span class="n">ret_elog_id</span>


<span class="k">def</span> <span class="nf">_save_history</span><span class="p">(</span>
    <span class="n">db</span><span class="p">,</span>
    <span class="n">md</span><span class="p">,</span>
    <span class="n">update_metadata_def</span><span class="p">,</span>
    <span class="n">atomic_type</span><span class="p">,</span>
    <span class="n">alg_name</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">alg_id</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">collection</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Save the processing history of a metadata object, which contains a key &quot;history&quot;.</span>

<span class="sd">    :param db: the database from which the data are to be written.</span>
<span class="sd">    :type db: :class:`mspasspy.db.database.Database`.</span>
<span class="sd">    :param md: the metadata of the target object.</span>
<span class="sd">    :type md: :class:`mspasspy.ccore.utility.Metadata`.</span>
<span class="sd">    :param update_metadata_def: the metadata schema to save.</span>
<span class="sd">    :type update_metadata_def: :class:`mspasspy.db.schema.MDSchemaDefinition`.</span>
<span class="sd">    :param atomic_type: the atomic type of the target object.</span>
<span class="sd">    :type atomic_type: :class:`mspasspy.ccore.utility.AtomicType`.</span>
<span class="sd">    :param collection: the collection that you want to store the history object. If not specified, use the defined</span>
<span class="sd">    collection in the schema.</span>
<span class="sd">    :return: current history_object_id.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># get the wf id name in the schema</span>
    <span class="n">wf_id_name</span> <span class="o">=</span> <span class="n">update_metadata_def</span><span class="o">.</span><span class="n">collection</span><span class="p">(</span><span class="s2">&quot;_id&quot;</span><span class="p">)</span> <span class="o">+</span> <span class="s2">&quot;_id&quot;</span>

    <span class="c1"># get the wf id in the mspass object</span>
    <span class="n">oid</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="k">if</span> <span class="s2">&quot;_id&quot;</span> <span class="ow">in</span> <span class="n">md</span><span class="p">:</span>
        <span class="n">oid</span> <span class="o">=</span> <span class="n">md</span><span class="p">[</span><span class="s2">&quot;_id&quot;</span><span class="p">]</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="n">collection</span><span class="p">:</span>
        <span class="n">collection</span> <span class="o">=</span> <span class="n">db</span><span class="o">.</span><span class="n">database_schema</span><span class="o">.</span><span class="n">default_name</span><span class="p">(</span><span class="s2">&quot;history_object&quot;</span><span class="p">)</span>
    <span class="n">history_col</span> <span class="o">=</span> <span class="n">db</span><span class="p">[</span><span class="n">collection</span><span class="p">]</span>

    <span class="n">proc_history</span> <span class="o">=</span> <span class="n">md</span><span class="p">[</span><span class="s2">&quot;history&quot;</span><span class="p">]</span>
    <span class="n">current_uuid</span> <span class="o">=</span> <span class="n">proc_history</span><span class="o">.</span><span class="n">id</span><span class="p">()</span>  <span class="c1"># uuid in the current node</span>
    <span class="n">current_nodedata</span> <span class="o">=</span> <span class="n">proc_history</span><span class="o">.</span><span class="n">current_nodedata</span><span class="p">()</span>
    <span class="c1"># get the alg_name and alg_id of current node</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">alg_id</span><span class="p">:</span>
        <span class="n">alg_id</span> <span class="o">=</span> <span class="n">current_nodedata</span><span class="o">.</span><span class="n">algid</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">alg_name</span><span class="p">:</span>
        <span class="n">alg_name</span> <span class="o">=</span> <span class="n">current_nodedata</span><span class="o">.</span><span class="n">algorithm</span>

    <span class="n">history_binary</span> <span class="o">=</span> <span class="n">pickle</span><span class="o">.</span><span class="n">dumps</span><span class="p">(</span><span class="n">proc_history</span><span class="p">)</span>
    <span class="c1"># todo save jobname jobid when global history module is done</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="c1"># construct the insert dict for saving into database</span>
        <span class="n">insert_dict</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s2">&quot;_id&quot;</span><span class="p">:</span> <span class="n">current_uuid</span><span class="p">,</span>
            <span class="s2">&quot;processing_history&quot;</span><span class="p">:</span> <span class="n">history_binary</span><span class="p">,</span>
            <span class="s2">&quot;alg_id&quot;</span><span class="p">:</span> <span class="n">alg_id</span><span class="p">,</span>
            <span class="s2">&quot;alg_name&quot;</span><span class="p">:</span> <span class="n">alg_name</span><span class="p">,</span>
        <span class="p">}</span>
        <span class="k">if</span> <span class="n">oid</span><span class="p">:</span>
            <span class="n">insert_dict</span><span class="p">[</span><span class="n">wf_id_name</span><span class="p">]</span> <span class="o">=</span> <span class="n">oid</span>
        <span class="c1"># insert new one</span>
        <span class="n">history_col</span><span class="o">.</span><span class="n">insert_one</span><span class="p">(</span><span class="n">insert_dict</span><span class="p">)</span>
    <span class="k">except</span> <span class="n">pymongo</span><span class="o">.</span><span class="n">errors</span><span class="o">.</span><span class="n">DuplicateKeyError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
        <span class="k">raise</span> <span class="n">MsPASSError</span><span class="p">(</span>
            <span class="s2">&quot;The history object to be saved has a duplicate uuid&quot;</span><span class="p">,</span> <span class="s2">&quot;Fatal&quot;</span>
        <span class="p">)</span> <span class="kn">from</span> <span class="nn">e</span>

    <span class="c1"># clear the history chain of the mspass object</span>
    <span class="n">md</span><span class="p">[</span><span class="s2">&quot;history&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">clear_history</span><span class="p">()</span>
    <span class="c1"># set_as_origin with uuid set to the newly generated id</span>
    <span class="n">md</span><span class="p">[</span><span class="s2">&quot;history&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">set_as_origin</span><span class="p">(</span><span class="n">alg_name</span><span class="p">,</span> <span class="n">alg_id</span><span class="p">,</span> <span class="n">current_uuid</span><span class="p">,</span> <span class="n">atomic_type</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">current_uuid</span>
</pre></div>

           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2020-2021, Ian Wang.</p>
  </div>

   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>